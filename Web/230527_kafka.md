## 카프카 기본 개념

### 카프카 내부 구조

![img](https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F6434aedf-f349-4cc1-800d-77c8e642eab9%2Fimage.png)

- 프로듀서: 데이터 파티션 내부 큐로 전송시킨다.
- 컨슈머: 파티션 내부 큐에서 데이터를 가져간다.
- 파티션: 데이터가 큐의 형태로 저장된다.
- 브로커: 컨트롤러 역할 및 데이터 저장/삭제를 수행한다.



### 카프카 사용의 장단점

카프카는 파이프라인으로 아래 장점을 가진다.

1. 확장성: 카프카는 수평적으로 확장 가능한 아키텍처를 제공하여 대규모 데이터 처리를 지원합니다. 분산된 클러스터를 구성하여 많은 양의 데이터를 처리하고 고성능을 유지할 수 있습니다.
2. 고가용성: 카프카는 데이터 손실을 최소화하기 위해 내구성과 복구 기능을 제공합니다. 데이터는 여러 브로커에 복제되며, 하나의 브로커가 고장나더라도 데이터의 안정성과 가용성이 유지됩니다.
3. 실시간 데이터 스트리밍: 카프카는 실시간 데이터 스트리밍을 지원하기 위해 설계되었습니다. 데이터는 실시간으로 처리되고, 다양한 응용 프로그램에서 실시간으로 데이터를 소비할 수 있습니다. 이는 빠른 응답 시간이 필요한 분석, 모니터링 및 대시보드 작업에 매우 유용합니다.
4. 다양한 데이터 소스 및 대상과의 통합: 카프카는 다양한 데이터 소스 및 대상과의 통합을 지원합니다. 대규모 데이터 스트림을 제공하며, 다양한 시스템 및 플랫폼 간에 데이터를 신속하게 전송할 수 있습니다.
5. 유연성과 확장성: 카프카는 다양한 소비자 그룹을 지원하여 여러 응용 프로그램이 동시에 데이터를 처리하고 소비할 수 있습니다. 데이터를 여러 처리 파이프라인에 전달할 수 있으며, 데이터 소비자의 수를 동적으로 조정하여 시스템의 유연성과 확장성을 높일 수 있습니다.
6. 생태계 및 커뮤니티: 카프카는 활발한 개발자 커뮤니티와 다양한 플러그인, 도구, 라이브러리, 프레임워크 등의 풍부한 생태계를 가지고 있습니다. 이는 빅데이터 파이프라인을 구축하고 운영하는 데 많은 지원을 제공하며, 사용자들 간의 정보 공유와 협력을 촉진합니다.

단점으로는 아래와 같다.

1. 학습 곡선과 복잡성: 카프카는 초보자에게는 학습 곡선이 높을 수 있습니다. 초기 설정 및 구성, 클러스터 관리 등의 작업은 상당한 복잡성을 가질 수 있으며, 관리 및 운영에 대한 전문 지식이 필요할 수 있습니다.
2. 추가적인 인프라 비용: 카프카를 사용하기 위해서는 클러스터를 구성해야하며, 이는 추가적인 인프라 비용을 발생시킬 수 있습니다. 클러스터 구성, 유지 보수 및 확장에 대한 리소스가 필요합니다.
3. 데이터 관리: 카프카는 데이터를 영구적으로 저장하지 않습니다. 따라서, 데이터의 유지 기간이나 데이터 관리 정책에 따라 데이터를 처리하거나 외부 저장소로 이동시켜야 할 수 있습니다.
4. 복제 지연: 카프카는 데이터를 여러 브로커에 복제하여 내고장성을 보장합니다. 하지만, 데이터의 복제 과정에서 약간의 지연이 발생할 수 있습니다. 따라서, 실시간 데이터 처리가 중요한 경우에는 이를 고려해야 합니다.
5. 운영 및 모니터링 복잡성: 큰 규모의 카프카 클러스터를 운영하고 모니터링하는 것은 복잡할 수 있습니다. 클러스터의 건강 상태, 처리량, 지연 등을 모니터링하고 성능 이슈를 해결하기 위해 추가적인 노력과 도구가 필요할 수 있습니다.



### 카프카 초기 구동 상황

1. Kafka 클러스터 시작: Kafka 클러스터는 여러 개의 브로커로 구성되어 있으며, 이들을 실행시켜야 합니다. 각 브로커는 `server.properties`와 같은 설정 파일을 기반으로 실행됩니다. 브로커를 실행하기 위해서는 ZooKeeper 서버가 먼저 실행되어야 하며, ZooKeeper 서버는 ZooKeeper 구성 파일인 `zookeeper.properties`를 사용하여 실행됩니다.
2. 토픽 생성: Kafka에 데이터를 저장할 토픽을 생성해야 합니다. 토픽 생성은 `kafka-topics.sh` 또는 `kafka-topics.bat`와 같은 Kafka 명령어를 사용하여 수행할 수 있습니다. 토픽 생성에는 토픽의 이름, 파티션 수, 복제본 수 등을 지정해야 합니다.
3. Producer 실행: 데이터를 생성하여 Kafka 클러스터로 전송할 Producer 애플리케이션을 실행합니다. Producer는 Kafka 클라이언트 라이브러리를 사용하여 작성되며, 필요한 설정과 연결 정보를 지정해야 합니다. Producer는 Kafka 클러스터에 데이터를 전송합니다.
4. Consumer 실행: Kafka 클러스터에서 데이터를 읽어오고 처리할 Consumer 애플리케이션을 실행합니다. Consumer 역시 Kafka 클라이언트 라이브러리를 사용하여 작성되며, 필요한 설정과 연결 정보를 지정해야 합니다. Consumer는 특정 토픽에서 데이터를 읽고 처리하는 로직을 포함하고 있습니다.
5. 데이터 처리: Consumer는 읽어온 데이터를 처리하는 로직을 구현해야 합니다. 이는 애플리케이션의 요구사항에 따라 달라집니다. 데이터 처리는 Consumer의 비즈니스 로직에 따라 이루어지며, 읽어온 데이터를 분석, 가공, 저장 등의 작업을 수행할 수 있습니다.



### 카프카 정상 동작 상황

1. 토픽(Topic) 생성: Kafka 클러스터에는 데이터를 저장하기 위한 토픽이 미리 생성되어 있어야 합니다. 토픽은 Producer가 데이터를 보내는 곳이며, Consumer가 데이터를 읽는 곳입니다.
2. Producer 등록: 애플리케이션에서 데이터를 생성하고 Kafka에 전송할 Producer를 등록합니다. Producer는 토픽에 대한 메시지를 생성하여 Kafka 클러스터로 보낼 수 있는 클라이언트입니다. Producer는 Kafka 브로커와 직접 통신하여 데이터를 보낼 수 있습니다.
3. Consumer 등록: 데이터를 읽어오기 위해 Consumer를 등록합니다. Consumer는 특정 토픽에서 데이터를 소비하고, 처리하는 클라이언트입니다. 여러 Consumer 그룹이 동시에 동일한 토픽을 읽을 수 있으며, 각 Consumer 그룹은 토픽의 파티션(Partition)에 대한 오프셋(Offset)을 관리합니다.
4. 데이터 생성 및 전송: Producer는 애플리케이션에서 데이터를 생성하고 Kafka 클러스터로 전송합니다. 데이터는 토픽에 대한 메시지로 패킹되며, 메시지는 Key-Value 형태로 구성될 수 있습니다. Producer는 토픽의 파티션을 직접 선택하거나, 메시지 Key의 해싱을 통해 파티션을 자동으로 선택할 수 있습니다.
5. 메시지 저장: Kafka 브로커는 수신한 메시지를 해당 토픽의 파티션에 저장합니다. 메시지는 토픽 내에서 파티션에 순서대로 추가됩니다. 파티션은 메시지의 순서를 보장하며, 각 파티션은 여러 개의 복제본(Replica)을 가질 수 있습니다.
6. Consumer 데이터 읽기: Consumer는 등록된 토픽의 파티션에서 데이터를 읽기 시작합니다. 각 Consumer 그룹은 파티션에 대한 오프셋을 추적하고, 아직 읽지 않은 메시지를 읽어오기 위해 오프셋을 조정합니다.
7. 데이터 처리: Consumer는 읽어온 데이터를 처리하고, 필요에 따라 애플리케이션에서 추가적인 작업을 수행합니다. 데이터 처리는 사용자 정의 로직에 따라 이루어집니다.
8. 커밋(Commit): Consumer 그룹은 처리한 메시지에 대한 오프셋을 커밋하여 Kafka에게 해당 오프셋을 알립니다. 이를 통해 Consumer 그룹은 다음에 다시 시작될 때 처리해야 할 오프셋을 추적하고 중복 처리를 방지할 수 있습니다.
9. 데이터 소비: Consumer 그룹이 오프셋을 커밋하면, 해당 오프셋 이후의 메시지들을 읽기 시작합니다. 이를 통해 데이터가 Consumer에게 전달되고 처리됩니다.



### 카프카 장애 상황

Kafka 클러스터에서 하나의 브로커 서버가 죽었을 때, 다음과 같은 일이 발생합니다. 아래는 순서대로 설명된 단계입니다:

1. 장애 감지: 클러스터의 다른 브로커나 모니터링 시스템은 브로커의 상태를 감지하고, 해당 브로커가 죽었다는 것을 인지합니다. 이는 네트워크 연결 끊김, 하트비트(Heartbeat) 손실 등의 방법을 통해 확인될 수 있습니다.
   1. 하트비트(Heartbeat): 각 브로커는 일정한 주기로 주키퍼에게 하트비트 신호를 보냅니다. 하트비트는 브로커가 활성 상태임을 나타내며, 주키퍼는 이를 받아 브로커의 상태를 감지합니다.
   2. 세션 타임아웃(Session Timeout): 브로커는 주키퍼에게 하트비트를 보내는 동안에도 정기적으로 세션 타임아웃 값을 재설정합니다. 만약 브로커가 정상적인 동작을 하지 않거나 연결이 끊어진 경우, 세션 타임아웃이 경과하면 주키퍼는 해당 브로커의 상태를 변경하여 장애로 판단합니다.
   3. 주키퍼 감시: 주키퍼는 클러스터의 브로커들과 연결되어 상태를 감시합니다. 만약 주키퍼가 특정 브로커로부터 하트비트 신호를 받지 못하거나 세션 타임아웃이 발생한 경우, 해당 브로커의 상태를 비활성화된 상태로 판단하고, 클러스터에서 제거할 수 있습니다.
   4. 리더 파티션 실패 감지: 주키퍼는 리더 파티션의 상태를 모니터링하고, 리더 파티션에 장애가 발생한 경우에는 해당 파티션의 리더를 재할당하는 작업을 수행합니다.
2. 리더 파티션 재할당: 죽은 브로커가 리더로 할당된 파티션들이 있을 경우, 클러스터 내의 다른 브로커들은 해당 파티션들에 대한 리더 역할을 다른 유효한 브로커로 재할당합니다. 이를 통해 데이터의 가용성과 내결함성을 유지할 수 있습니다.
3. ISR(In-Sync Replicas) 업데이트: ISR은 리더와 동기화된 복제본을 나타내는 집합입니다. 죽은 브로커가 ISR에 속한 복제본을 가지고 있었다면, 해당 복제본은 ISR에서 제외됩니다. 이는 클러스터의 데이터 복제를 유지하면서 죽은 브로커에 의존하지 않도록 합니다.
4. 프로듀서와 컨슈머의 재연결: 죽은 브로커와 연결되어 있던 프로듀서와 컨슈머는 해당 브로커와의 연결이 끊겼다는 것을 인지하고, 재연결을 시도합니다. 이 때, 주키퍼와의 상호작용을 통해 업데이트된 메타데이터를 얻어와 새로운 리더 파티션 정보를 알아냅니다.
   1. 연결 끊김 감지: 프로듀서와 컨슈머는 주기적으로 브로커와의 연결 상태를 확인합니다. 만약 브로커와의 연결이 끊어진 것을 감지하면, 장애 상황으로 판단하고 재연결을 시도합니다.
   2. 주키퍼와의 상호작용: 프로듀서와 컨슈머는 주키퍼에게 메타데이터를 조회하고 업데이트된 정보를 얻기 위해 상호작용합니다. 장애 상황에서는 주키퍼를 통해 새로운 메타데이터를 얻어옵니다. 이는 새로운 파티션 할당 정보, 리더 파티션 정보 등을 포함합니다.
   3. 브로커 재연결: 프로듀서와 컨슈머는 업데이트된 메타데이터를 바탕으로 새로운 브로커와의 연결을 시도합니다. 이때, 장애로 인해 이전에 연결되었던 브로커와는 다른 브로커에 연결될 수 있습니다.
   4. 메시지 처리 재개: 재연결에 성공한 프로듀서는 새로운 브로커에게 데이터를 전송하고, 컨슈머는 새로운 브로커에서 데이터를 읽어옵니다. 장애로 인해 발생한 메시지 손실을 최소화하기 위해 컨슈머는 재연결 후에 중단된 오프셋(Offset)에서부터 메시지 처리를 재개합니다.
5. 브로커 복구: 죽은 브로커가 복구되거나 대체 브로커가 새로 추가되면, 해당 브로커는 클러스터에 다시 참여하고 파티션의 리더 또는 복제본 역할을 맡을 수 있습니다.



## 카프카 클러스터

### 클러스터에 속한것

Kafka 클러스터는 Apache Kafka 시스템을 구성하는 여러 개의 브로커로 구성된 분산 시스템입니다. 각각의 브로커는 고성능의 메시지 브로커 역할을 수행하며, 데이터의 안정적이고 신속한 전달을 위해 메시지를 저장하고 전송합니다.

Kafka 클러스터의 주요 구성 요소는 다음과 같습니다:

1. **브로커 (Broker)**: Kafka 클러스터의 기본 단위로, 메시지를 저장하고 전달하는 서버입니다. 여러 개의 브로커로 구성되며, 각 브로커는 고유한 ID를 가지고 있습니다. 브로커는 데이터를 토픽 단위로 파티션에 분산 저장하고, 클러스터 내의 다른 브로커들과 통신하여 데이터를 복제합니다.
2. **토픽 (Topic)**: Kafka에서 데이터를 주고받는 주요 단위입니다. 토픽은 메시지의 유사한 카테고리 또는 주제를 나타내며, 사용자가 정의할 수 있습니다. 각 토픽은 여러 개의 파티션으로 나누어질 수 있습니다.
3. **파티션 (Partition)**: 토픽은 파티션으로 나뉘어지며, 각 파티션은 순서가 있는 메시지의 일련을 나타냅니다. 파티션은 브로커들 사이에 분산되어 저장되며, 데이터의 처리량과 확장성을 높이는 역할을 합니다.
4. **리플리카 (Replica)**: 파티션은 여러 개의 리플리카로 구성될 수 있습니다. 각 리플리카는 동일한 파티션의 데이터의 복사본을 나타냅니다. 리플리카는 데이터의 내구성과 고가용성을 보장하기 위해 사용됩니다.
5. **프로듀서 (Producer)**: Kafka에 데이터를 생성하여 토픽으로 전송하는 클라이언트 애플리케이션입니다. 프로듀서는 메시지를 특정 토픽에 보내고, 필요한 경우 파티션 및 오프셋을 지정할 수 있습니다.
6. **컨슈머 (Consumer)**: Kafka에서 데이터를 소비하는 클라이언트 애플리케이션입니다. 컨슈머는 특정 토픽에서 메시지를 읽고 처리합니다. 여러 개의 컨슈머 그룹을 구성하여 동시에 데이터를 처리할 수 있습니다.

Kafka 클러스터는 대량의 데이터를 처리하고, 데이터의 안정적인 전달과 복제를 보장하기 위해 분산 아키텍처를 사용합니다. 브로커들은 자체적으로 클러스터의 메타데이터와 상태를 관리하며, 클러스터의 신뢰성과 확장성을 제공합니다.

### 클러스터가 아닌것

Kafka를 운영하기 위한 아키텍처에서 Kafka 클러스터에 직접적으로 속하지 않는 구성 요소는 다음과 같습니다:

1. **ZooKeeper**: Kafka 클러스터의 구성 관리와 리더 선출을 담당하는 분산 코디네이터인 ZooKeeper는 Kafka 클러스터에 속하지 않습니다. 그러나 Kafka 클러스터는 ZooKeeper를 의존하여 메타데이터와 상태 정보를 관리하고, 브로커들 간의 조정을 수행합니다.
2. **Producer**: Kafka 프로듀서는 Kafka 클러스터의 외부에 위치한 애플리케이션 또는 서비스입니다. 프로듀서는 Kafka 브로커로 데이터를 생성하고 전송합니다. Kafka 클러스터의 일부가 아니며, 데이터를 생성하고 전송하는 역할을 수행합니다.
3. **Consumer**: Kafka 컨슈머도 Kafka 클러스터의 외부에 위치한 애플리케이션 또는 서비스입니다. 컨슈머는 Kafka 토픽에서 데이터를 소비하고 처리합니다. Kafka 클러스터의 일부가 아니며, 데이터를 소비하고 처리하는 역할을 수행합니다.
4. **Kafka Connect**: Kafka Connect는 데이터 소스와 Kafka 클러스터를 연결해주는 분산 데이터 통합 프레임워크입니다. Kafka Connect는 Kafka 클러스터와 독립적으로 실행되며, 다양한 소스 및 대상 시스템과의 데이터 이동을 관리합니다.
5. **Kafka Streams**: Kafka Streams는 스트리밍 애플리케이션을 구축하기 위한 클라이언트 라이브러리입니다. Kafka Streams 애플리케이션은 Kafka 클러스터와 독립적으로 실행되며, 스트리밍 데이터 처리를 위한 기능을 제공합니다.

이러한 구성 요소들은 Kafka 클러스터와 상호 작용하며, Kafka에서 데이터를 생성, 전송, 소비 및 처리하기 위해 필요한 역할을 수행합니다. 그러나 직접적으로 Kafka 클러스터에 속하는 것은 아니며, 독립적으로 실행되거나 외부 시스템과의 상호 작용을 담당합니다.



## 카프카 CLI



## 프로듀서 App



## 컨슈머 App



## 멱등성 프로듀서



## 스트림즈



## 커넥트



## 아키텍처