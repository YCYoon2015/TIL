## 카프카 기본 개념

### 카프카 내부 구조

![img](https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F6434aedf-f349-4cc1-800d-77c8e642eab9%2Fimage.png)

- 프로듀서: 데이터 파티션 내부 큐로 전송시킨다.
- 컨슈머: 파티션 내부 큐에서 데이터를 가져간다.
- 파티션: 데이터가 큐의 형태로 저장된다.
- 브로커: 컨트롤러 역할 및 데이터 저장/삭제를 수행한다.



### 카프카 사용의 장단점

카프카는 파이프라인으로 아래 장점을 가진다.

1. 확장성: 카프카는 수평적으로 확장 가능한 아키텍처를 제공하여 대규모 데이터 처리를 지원합니다. 분산된 클러스터를 구성하여 많은 양의 데이터를 처리하고 고성능을 유지할 수 있습니다.
2. 고가용성: 카프카는 데이터 손실을 최소화하기 위해 내구성과 복구 기능을 제공합니다. 데이터는 여러 브로커에 복제되며, 하나의 브로커가 고장나더라도 데이터의 안정성과 가용성이 유지됩니다.
3. 실시간 데이터 스트리밍: 카프카는 실시간 데이터 스트리밍을 지원하기 위해 설계되었습니다. 데이터는 실시간으로 처리되고, 다양한 응용 프로그램에서 실시간으로 데이터를 소비할 수 있습니다. 이는 빠른 응답 시간이 필요한 분석, 모니터링 및 대시보드 작업에 매우 유용합니다.
4. 다양한 데이터 소스 및 대상과의 통합: 카프카는 다양한 데이터 소스 및 대상과의 통합을 지원합니다. 대규모 데이터 스트림을 제공하며, 다양한 시스템 및 플랫폼 간에 데이터를 신속하게 전송할 수 있습니다.
5. 유연성과 확장성: 카프카는 다양한 소비자 그룹을 지원하여 여러 응용 프로그램이 동시에 데이터를 처리하고 소비할 수 있습니다. 데이터를 여러 처리 파이프라인에 전달할 수 있으며, 데이터 소비자의 수를 동적으로 조정하여 시스템의 유연성과 확장성을 높일 수 있습니다.
6. 생태계 및 커뮤니티: 카프카는 활발한 개발자 커뮤니티와 다양한 플러그인, 도구, 라이브러리, 프레임워크 등의 풍부한 생태계를 가지고 있습니다. 이는 빅데이터 파이프라인을 구축하고 운영하는 데 많은 지원을 제공하며, 사용자들 간의 정보 공유와 협력을 촉진합니다.

단점으로는 아래와 같다.

1. 학습 곡선과 복잡성: 카프카는 초보자에게는 학습 곡선이 높을 수 있습니다. 초기 설정 및 구성, 클러스터 관리 등의 작업은 상당한 복잡성을 가질 수 있으며, 관리 및 운영에 대한 전문 지식이 필요할 수 있습니다.
2. 추가적인 인프라 비용: 카프카를 사용하기 위해서는 클러스터를 구성해야하며, 이는 추가적인 인프라 비용을 발생시킬 수 있습니다. 클러스터 구성, 유지 보수 및 확장에 대한 리소스가 필요합니다.
3. 데이터 관리: 카프카는 데이터를 영구적으로 저장하지 않습니다. 따라서, 데이터의 유지 기간이나 데이터 관리 정책에 따라 데이터를 처리하거나 외부 저장소로 이동시켜야 할 수 있습니다.
4. 복제 지연: 카프카는 데이터를 여러 브로커에 복제하여 내고장성을 보장합니다. 하지만, 데이터의 복제 과정에서 약간의 지연이 발생할 수 있습니다. 따라서, 실시간 데이터 처리가 중요한 경우에는 이를 고려해야 합니다.
5. 운영 및 모니터링 복잡성: 큰 규모의 카프카 클러스터를 운영하고 모니터링하는 것은 복잡할 수 있습니다. 클러스터의 건강 상태, 처리량, 지연 등을 모니터링하고 성능 이슈를 해결하기 위해 추가적인 노력과 도구가 필요할 수 있습니다.



### 카프카 초기 구동

1. Kafka 클러스터 시작: Kafka 클러스터는 여러 개의 브로커로 구성되어 있으며, 이들을 실행시켜야 합니다. 각 브로커는 `server.properties`와 같은 설정 파일을 기반으로 실행됩니다. 브로커를 실행하기 위해서는 ZooKeeper 서버가 먼저 실행되어야 하며, ZooKeeper 서버는 ZooKeeper 구성 파일인 `zookeeper.properties`를 사용하여 실행됩니다.
2. 토픽 생성: Kafka에 데이터를 저장할 토픽을 생성해야 합니다. 토픽 생성은 `kafka-topics.sh` 또는 `kafka-topics.bat`와 같은 Kafka 명령어를 사용하여 수행할 수 있습니다. 토픽 생성에는 토픽의 이름, 파티션 수, 복제본 수 등을 지정해야 합니다.
3. Producer 실행: 데이터를 생성하여 Kafka 클러스터로 전송할 Producer 애플리케이션을 실행합니다. Producer는 Kafka 클라이언트 라이브러리를 사용하여 작성되며, 필요한 설정과 연결 정보를 지정해야 합니다. Producer는 Kafka 클러스터에 데이터를 전송합니다.
4. Consumer 실행: Kafka 클러스터에서 데이터를 읽어오고 처리할 Consumer 애플리케이션을 실행합니다. Consumer 역시 Kafka 클라이언트 라이브러리를 사용하여 작성되며, 필요한 설정과 연결 정보를 지정해야 합니다. Consumer는 특정 토픽에서 데이터를 읽고 처리하는 로직을 포함하고 있습니다.
5. 데이터 처리: Consumer는 읽어온 데이터를 처리하는 로직을 구현해야 합니다. 이는 애플리케이션의 요구사항에 따라 달라집니다. 데이터 처리는 Consumer의 비즈니스 로직에 따라 이루어지며, 읽어온 데이터를 분석, 가공, 저장 등의 작업을 수행할 수 있습니다.



### 카프카 정상 동작 상황

1. 토픽(Topic) 생성: Kafka 클러스터에는 데이터를 저장하기 위한 토픽이 미리 생성되어 있어야 합니다. 토픽은 Producer가 데이터를 보내는 곳이며, Consumer가 데이터를 읽는 곳입니다.
2. Producer 등록: 애플리케이션에서 데이터를 생성하고 Kafka에 전송할 Producer를 등록합니다. Producer는 토픽에 대한 메시지를 생성하여 Kafka 클러스터로 보낼 수 있는 클라이언트입니다. Producer는 Kafka 브로커와 직접 통신하여 데이터를 보낼 수 있습니다.
3. Consumer 등록: 데이터를 읽어오기 위해 Consumer를 등록합니다. Consumer는 특정 토픽에서 데이터를 소비하고, 처리하는 클라이언트입니다. 여러 Consumer 그룹이 동시에 동일한 토픽을 읽을 수 있으며, 각 Consumer 그룹은 토픽의 파티션(Partition)에 대한 오프셋(Offset)을 관리합니다.
4. 데이터 생성 및 전송: Producer는 애플리케이션에서 데이터를 생성하고 Kafka 클러스터로 전송합니다. 데이터는 토픽에 대한 메시지로 패킹되며, 메시지는 Key-Value 형태로 구성될 수 있습니다. Producer는 토픽의 파티션을 직접 선택하거나, 메시지 Key의 해싱을 통해 파티션을 자동으로 선택할 수 있습니다.
5. 메시지 저장: Kafka 브로커는 수신한 메시지를 해당 토픽의 파티션에 저장합니다. 메시지는 토픽 내에서 파티션에 순서대로 추가됩니다. 파티션은 메시지의 순서를 보장하며, 각 파티션은 여러 개의 복제본(Replica)을 가질 수 있습니다.
6. Consumer 데이터 읽기: Consumer는 등록된 토픽의 파티션에서 데이터를 읽기 시작합니다. 각 Consumer 그룹은 파티션에 대한 오프셋을 추적하고, 아직 읽지 않은 메시지를 읽어오기 위해 오프셋을 조정합니다.
7. 데이터 처리: Consumer는 읽어온 데이터를 처리하고, 필요에 따라 애플리케이션에서 추가적인 작업을 수행합니다. 데이터 처리는 사용자 정의 로직에 따라 이루어집니다.
8. 커밋(Commit): Consumer 그룹은 처리한 메시지에 대한 오프셋을 커밋하여 Kafka에게 해당 오프셋을 알립니다. 이를 통해 Consumer 그룹은 다음에 다시 시작될 때 처리해야 할 오프셋을 추적하고 중복 처리를 방지할 수 있습니다.
9. 데이터 소비: Consumer 그룹이 오프셋을 커밋하면, 해당 오프셋 이후의 메시지들을 읽기 시작합니다. 이를 통해 데이터가 Consumer에게 전달되고 처리됩니다.



### 카프카 장애 상황

Kafka 클러스터에서 하나의 브로커 서버가 죽었을 때, 다음과 같은 일이 발생합니다. 아래는 순서대로 설명된 단계입니다:

1. 장애 감지: 클러스터의 다른 브로커나 모니터링 시스템은 브로커의 상태를 감지하고, 해당 브로커가 죽었다는 것을 인지합니다. 이는 네트워크 연결 끊김, 하트비트(Heartbeat) 손실 등의 방법을 통해 확인될 수 있습니다.
   - 하트비트(Heartbeat): 각 브로커는 일정한 주기로 주키퍼에게 하트비트 신호를 보냅니다. 하트비트는 브로커가 활성 상태임을 나타내며, 주키퍼는 이를 받아 브로커의 상태를 감지합니다.
   - 세션 타임아웃(Session Timeout): 브로커는 주키퍼에게 하트비트를 보내는 동안에도 정기적으로 세션 타임아웃 값을 재설정합니다. 만약 브로커가 정상적인 동작을 하지 않거나 연결이 끊어진 경우, 세션 타임아웃이 경과하면 주키퍼는 해당 브로커의 상태를 변경하여 장애로 판단합니다.
   - 주키퍼 감시: 주키퍼는 클러스터의 브로커들과 연결되어 상태를 감시합니다. 만약 주키퍼가 특정 브로커로부터 하트비트 신호를 받지 못하거나 세션 타임아웃이 발생한 경우, 해당 브로커의 상태를 비활성화된 상태로 판단하고, 클러스터에서 제거할 수 있습니다.
   - 리더 파티션 실패 감지: 주키퍼는 리더 파티션의 상태를 모니터링하고, 리더 파티션에 장애가 발생한 경우에는 해당 파티션의 리더를 재할당하는 작업을 수행합니다.
2. 리더 파티션 재할당: 죽은 브로커가 리더로 할당된 파티션들이 있을 경우, 클러스터 내의 다른 브로커들은 해당 파티션들에 대한 리더 역할을 다른 유효한 브로커로 재할당합니다. 이를 통해 데이터의 가용성과 내결함성을 유지할 수 있습니다.
3. ISR(In-Sync Replicas) 업데이트: ISR은 리더와 동기화된 복제본을 나타내는 집합입니다. 죽은 브로커가 ISR에 속한 복제본을 가지고 있었다면, 해당 복제본은 ISR에서 제외됩니다. 이는 클러스터의 데이터 복제를 유지하면서 죽은 브로커에 의존하지 않도록 합니다.
4. 프로듀서와 컨슈머의 재연결: 죽은 브로커와 연결되어 있던 프로듀서와 컨슈머는 해당 브로커와의 연결이 끊겼다는 것을 인지하고, 재연결을 시도합니다. 이 때, 주키퍼와의 상호작용을 통해 업데이트된 메타데이터를 얻어와 새로운 리더 파티션 정보를 알아냅니다.
   - 연결 끊김 감지: 프로듀서와 컨슈머는 주기적으로 브로커와의 연결 상태를 확인합니다. 만약 브로커와의 연결이 끊어진 것을 감지하면, 장애 상황으로 판단하고 재연결을 시도합니다.
   - 주키퍼와의 상호작용: 프로듀서와 컨슈머는 주키퍼에게 메타데이터를 조회하고 업데이트된 정보를 얻기 위해 상호작용합니다. 장애 상황에서는 주키퍼를 통해 새로운 메타데이터를 얻어옵니다. 이는 새로운 파티션 할당 정보, 리더 파티션 정보 등을 포함합니다.
   - 브로커 재연결: 프로듀서와 컨슈머는 업데이트된 메타데이터를 바탕으로 새로운 브로커와의 연결을 시도합니다. 이때, 장애로 인해 이전에 연결되었던 브로커와는 다른 브로커에 연결될 수 있습니다.
   - 메시지 처리 재개: 재연결에 성공한 프로듀서는 새로운 브로커에게 데이터를 전송하고, 컨슈머는 새로운 브로커에서 데이터를 읽어옵니다. 장애로 인해 발생한 메시지 손실을 최소화하기 위해 컨슈머는 재연결 후에 중단된 오프셋(Offset)에서부터 메시지 처리를 재개합니다.
5. 브로커 복구: 죽은 브로커가 복구되거나 대체 브로커가 새로 추가되면, 해당 브로커는 클러스터에 다시 참여하고 파티션의 리더 또는 복제본 역할을 맡을 수 있습니다.

### SaaS가 아닌 오픈소스만으로 사용 시 고려할 점

1. 하드웨어 요구 사항: Kafka는 대량의 데이터를 처리하기 때문에 충분한 처리 능력과 저장 공간이 필요합니다. 클러스터의 크기와 예상 데이터 스트림의 양에 맞게 서버 하드웨어를 선택해야 합니다.
2. 네트워크 구성: Kafka 클러스터는 고성능 및 안정적인 네트워크 연결을 필요로 합니다. 빠른 데이터 전송을 위해 클라이언트와 브로커 사이의 네트워크 대역폭과 지연 시간을 고려해야 합니다.
3. 데이터 백업 및 복구: Kafka는 데이터의 내구성을 보장하기 위해 복제 및 복구 메커니즘을 제공합니다. 데이터를 안전하게 보호하고 장애 복구를 위한 백업 및 복구 전략을 수립해야 합니다.
4. 보안: Kafka에는 데이터 흐름을 보호하기 위한 보안 기능이 포함되어 있습니다. SSL/TLS를 사용하여 네트워크 통신을 암호화하고, 클라이언트 인증 및 접근 제어를 설정하여 데이터의 기밀성과 무결성을 유지해야 합니다.
5. 클러스터 구성 및 모니터링: Kafka 클러스터는 여러 브로커로 구성되며, 이들을 적절하게 구성하고 관리해야 합니다. 클러스터의 상태와 성능을 모니터링하고, 필요한 경우 스케일링 및 리밸런싱을 수행하여 최적의 성능을 유지할 수 있도록 해야 합니다.
   - Broker 상태: Kafka 클러스터의 브로커 상태를 모니터링해야 합니다. 브로커의 가용성, 처리량, CPU 및 메모리 사용량, 디스크 사용량 등을 확인하여 잠재적인 문제를 식별하고 대응할 수 있습니다.
   - Topic 및 Partition 상태: Kafka는 Topic과 Partition으로 데이터를 구성합니다. 각 Topic과 Partition의 상태를 모니터링하여 데이터 유실, 복제 지연, 특정 Partition의 부하 집중 등의 문제를 감지할 수 있습니다.
   - Producer 및 Consumer 상태: Kafka Producer 및 Consumer의 상태를 모니터링하여 데이터 흐름에 문제가 발생하는지 확인할 수 있습니다. Producer의 전송률, 에러율, Consumer의 읽기 속도, 오프셋 커밋 상태 등을 모니터링해야 합니다.
   - Network 상태: Kafka는 네트워크를 통해 데이터를 전송합니다. 네트워크 대역폭, 지연 시간, 패킷 손실 등과 같은 네트워크 지표를 모니터링하여 데이터 전송 성능에 영향을 미치는 문제를 식별할 수 있습니다.
   - 리밸런싱 상태: Kafka 클러스터는 브로커 추가 또는 삭제, Topic 구성 변경 등의 이벤트에 따라 리밸런싱이 발생할 수 있습니다. 리밸런싱 상태를 모니터링하여 클러스터의 안정성과 데이터 분배가 올바르게 유지되는지 확인해야 합니다.
   - 지연 및 지표 추이: Kafka 클러스터의 지연 시간, 처리량, 에러율 등의 지표를 추적하여 시간 경과에 따른 성능 변화를 분석할 수 있습니다. 이를 통해 예측 및 용량 계획을 수립하고 성능 개선을 위한 조치를 취할 수 있습니다.
   - 로그 및 경고: Kafka 로그와 모니터링 도구에서 제공하는 경고를 확인하여 잠재적인 문제를 탐지할 수 있습니다. 로그 분석 및 경고 설정을 통해 프로덕션 환경에서 발생하는 이상 상황을 조기에 감지하고 대응할 수 있습니다.
6. 운영 및 유지보수: Kafka 클러스터의 운영과 유지보수는 주기적인 작업을 필요로 합니다. 메시지 보존 정책 설정, 로그 파일 관리, 시스템 패치 및 업그레이드 등의 작업을 계획하고 수행해야 합니다.
7. 커뮤니티 지원: Kafka는 활발한 개발자 커뮤니티와 오픈소스 생태계를 가지고 있습니다. 문제 발생 시 온라인 포럼, 메일링 리스트, 블로그 등에서 지원을 받을 수 있으며, 이러한 자원들을 활용하여 문제 해결과 최적화를 도모할 수 있습니다.





## 카프카 클러스터

### 클러스터에 속한것

Kafka 클러스터는 Apache Kafka 시스템을 구성하는 여러 개의 브로커로 구성된 분산 시스템입니다. 각각의 브로커는 고성능의 메시지 브로커 역할을 수행하며, 데이터의 안정적이고 신속한 전달을 위해 메시지를 저장하고 전송합니다.

Kafka 클러스터의 주요 구성 요소는 다음과 같습니다:

1. **브로커 (Broker)**: Kafka 클러스터의 기본 단위로, 메시지를 저장하고 전달하는 서버입니다. 여러 개의 브로커로 구성되며, 각 브로커는 고유한 ID를 가지고 있습니다. 브로커는 데이터를 토픽 단위로 파티션에 분산 저장하고, 클러스터 내의 다른 브로커들과 통신하여 데이터를 복제합니다.
2. **토픽 (Topic)**: Kafka에서 데이터를 주고받는 주요 단위입니다. 토픽은 메시지의 유사한 카테고리 또는 주제를 나타내며, 사용자가 정의할 수 있습니다. 각 토픽은 여러 개의 파티션으로 나누어질 수 있습니다.
3. **파티션 (Partition)**: 토픽은 파티션으로 나뉘어지며, 각 파티션은 순서가 있는 메시지의 일련을 나타냅니다. 파티션은 브로커들 사이에 분산되어 저장되며, 데이터의 처리량과 확장성을 높이는 역할을 합니다.
4. **리플리카 (Replica)**: 파티션은 여러 개의 리플리카로 구성될 수 있습니다. 각 리플리카는 동일한 파티션의 데이터의 복사본을 나타냅니다. 리플리카는 데이터의 내구성과 고가용성을 보장하기 위해 사용됩니다.
5. **프로듀서 (Producer)**: Kafka에 데이터를 생성하여 토픽으로 전송하는 클라이언트 애플리케이션입니다. 프로듀서는 메시지를 특정 토픽에 보내고, 필요한 경우 파티션 및 오프셋을 지정할 수 있습니다.
6. **컨슈머 (Consumer)**: Kafka에서 데이터를 소비하는 클라이언트 애플리케이션입니다. 컨슈머는 특정 토픽에서 메시지를 읽고 처리합니다. 여러 개의 컨슈머 그룹을 구성하여 동시에 데이터를 처리할 수 있습니다.

Kafka 클러스터는 대량의 데이터를 처리하고, 데이터의 안정적인 전달과 복제를 보장하기 위해 분산 아키텍처를 사용합니다. 브로커들은 자체적으로 클러스터의 메타데이터와 상태를 관리하며, 클러스터의 신뢰성과 확장성을 제공합니다.

### 클러스터가 아닌것

Kafka를 운영하기 위한 아키텍처에서 Kafka 클러스터에 직접적으로 속하지 않는 구성 요소는 다음과 같습니다:

1. **ZooKeeper**: Kafka 클러스터의 구성 관리와 리더 선출을 담당하는 분산 코디네이터인 ZooKeeper는 Kafka 클러스터에 속하지 않습니다. 그러나 Kafka 클러스터는 ZooKeeper를 의존하여 메타데이터와 상태 정보를 관리하고, 브로커들 간의 조정을 수행합니다.
2. **Producer**: Kafka 프로듀서는 Kafka 클러스터의 외부에 위치한 애플리케이션 또는 서비스입니다. 프로듀서는 Kafka 브로커로 데이터를 생성하고 전송합니다. Kafka 클러스터의 일부가 아니며, 데이터를 생성하고 전송하는 역할을 수행합니다.
3. **Consumer**: Kafka 컨슈머도 Kafka 클러스터의 외부에 위치한 애플리케이션 또는 서비스입니다. 컨슈머는 Kafka 토픽에서 데이터를 소비하고 처리합니다. Kafka 클러스터의 일부가 아니며, 데이터를 소비하고 처리하는 역할을 수행합니다.
4. **Kafka Connect**: Kafka Connect는 데이터 소스와 Kafka 클러스터를 연결해주는 분산 데이터 통합 프레임워크입니다. Kafka Connect는 Kafka 클러스터와 독립적으로 실행되며, 다양한 소스 및 대상 시스템과의 데이터 이동을 관리합니다.
5. **Kafka Streams**: Kafka Streams는 스트리밍 애플리케이션을 구축하기 위한 클라이언트 라이브러리입니다. Kafka Streams 애플리케이션은 Kafka 클러스터와 독립적으로 실행되며, 스트리밍 데이터 처리를 위한 기능을 제공합니다.

이러한 구성 요소들은 Kafka 클러스터와 상호 작용하며, Kafka에서 데이터를 생성, 전송, 소비 및 처리하기 위해 필요한 역할을 수행합니다. 그러나 직접적으로 Kafka 클러스터에 속하는 것은 아니며, 독립적으로 실행되거나 외부 시스템과의 상호 작용을 담당합니다.



## 카프카 CLI

카프카 설치: https://jyoondev.tistory.com/184

### 실행

```
#zookeeper 실행
bin/zookeeper-server-start.sh config/zookeeper.properties

#broker 실행
bin/kafka-server-start.sh config/server.properties

#topic 생성
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic hello.kafka

#(조건추가) topic 생성
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 10 --replication-factor 1 --topic hello.kafka2 --config retention.ms=172800000

```

### 확인

```
#broker 확인
bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092

#topic 확인
bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic hello.kafka --describe

#broker의 설정값 확인 
bin/kafka-configs.sh --bootstrap-server localhost:9092 --broker 0 --all --describe

```

### 변경

```
#topic partitions 증가 (hello.kafka를 10으로 증가)
bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic hello.kafka --alter --partitions 10

#topic 옵션 변경 (hello.kafka 변경)
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config min.insync.replicas=2 --topic hello.kafka

```

### 테스트

```
#Topic에 데이터 입력창 접속
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic hello.kafka

#(key 구분자 추가) Topic에 데이터 입력창 접속
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic hello.kafka --property "parse.key=true" --property "key.separator=:"

#Topic 내용 확인 (전체)
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic hello.kafka --from-beginning

```





## 프로듀서 App

### 알아두기

- 파티션 개수가 변경되는경우 동일키-파티션 매칭이 깨질 수 있다.

  

### 설정 옵션

#### 필수값

1. `bootstrap.servers`: 이 옵션은 Kafka 클러스터의 브로커 목록을 지정합니다. 프로듀서가 클러스터와 통신하기 위해 적어도 하나의 브로커 주소가 필요합니다.
2. `key.serializer`: 이 옵션은 프로듀서가 메시지 키를 직렬화하는 데 사용되는 직렬화 클래스를 지정합니다. 일반적으로 `org.apache.kafka.common.serialization.StringSerializer`와 같은 클래스를 사용하여 문자열 키를 직렬화합니다.
3. `value.serializer`: 이 옵션은 프로듀서가 메시지 값을 직렬화하는 데 사용되는 직렬화 클래스를 지정합니다. 마찬가지로, 일반적으로 `org.apache.kafka.common.serialization.StringSerializer`와 같은 클래스를 사용하여 문자열 값을 직렬화합니다.

#### 옵션값

1. `acks`: 이 옵션은 프로듀서가 메시지 전송을 성공으로 간주하기 위해 필요한 브로커의 확인 수를 지정합니다. 값으로 `all`, `1`, `0` 등을 설정할 수 있으며, 이는 각각 "모든 복제본이 확인을 해야 함", "최소한 한 개의 복제본이 확인을 해야 함(리더 파티션 확인하게 됨)", "확인을 기다리지 않음"을 의미합니다.

   일반적으로 1로 설정해서 운영하는 경우가 많다. 너무 높다면, 빠른 트래픽을 감당할 수 없다.

2. `compression.type`: 이 옵션은 프로듀서가 메시지를 압축하는 방법을 지정합니다. 압축을 사용하면 네트워크 대역폭을 절약할 수 있습니다. 일반적으로 `"none"`, `"gzip"`, `"snappy"`, `"lz4"`, `"zstd"`와 같은 압축 알고리즘을 지정할 수 있습니다.

3. `batch.size`: 이 옵션은 프로듀서가 단일 파티션에 대해 배치로 전송할 메시지 크기를 지정합니다. 메시지를 배치로 그룹화하여 대량 전송할 수 있으며, 이를 통해 네트워크 부하를 줄이고 전송 성능을 향상시킬 수 있습니다.

4. `linger.ms`: 이 옵션은 프로듀서가 배치를 전송하기 전에 대기하는 최대 시간을 지정합니다. 이를 통해 작은 메시지들을 모아서 큰 배치로 전송할 수 있으며, 효율성을 높일 수 있습니다.

5. `max.in.flight.requests.per.connection`: 이 옵션은 프로듀서가 동시에 브로커로 보낼 수 있는 요청의 최대 수를 제한합니다. 이를 통해 순서가 중요한 메시지를 제어하고, 프로듀서의 처리량을 조절할 수 있습니다.

6. `retries`: 이 옵션은 프로듀서가 메시지 전송 중에 실패한 경우 재시도할 횟수를 지정합니다. 이를 통해 네트워크 문제 또는 임시적인 오류로 인해 메시지가 손실되는 경우에도 안정성을 제공할 수 있습니다. 기본값은 2147483647이다. 안정성이 낮아도 된다면 0이나 작은수를 사용하면된다.

7. `max.block.ms`: 이 옵션은 프로듀서가 브로커에게 메시지를 보내지 못한 경우 대기할 최대 시간을 제어합니다. 이 값을 설정하면 메시지 전송이 불가능한 경우에도 프로듀서가 계속 실행되도록 조정할 수 있습니다.

8. `partitioner.class`: 이 옵션은 프로듀서가 메시지를 어떤 파티션에 보낼지 결정하는 파티셔너 클래스를 지정합니다. 기본적으로 파티셔너를 제공하지만, 사용자 정의 파티셔너를 구현하여 메시지 분배를 제어할 수도 있습니다.



### Java코드

#### 라이브러리

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>2.5.0</version>
    </dependency>
</dependencies>
```

#### 기본 코드

```java
import org.apache.kafka.clients.producer.*;

import java.util.Properties;

public class KafkaProducerExample {

    public static void main(String[] args) {
        // Kafka 클러스터의 브로커 목록
        String bootstrapServers = "localhost:9092";

        // 프로듀서 설정
        Properties properties = new Properties();
        properties.put("bootstrap.servers", bootstrapServers);
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽과 메시지
        String topic = "my-topic";
        String message = "Hello, Kafka!";

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, message);

        // 메시지 전송
        producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    System.out.println("메시지 전송 실패: " + exception.getMessage());
                } else {
                    System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
                }
            }
        });

        // 프로듀서 종료
        producer.close(); // flush 포함됨
    }
}

```

#### 메시지 키 추가

```java
		// 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽, 키, 메시지
        String topic = "my-topic";
        String key = "my-key";
        String message = "Hello, Kafka!";

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, message);
```

#### 파티션 번호 지정

```java
        // 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽, 키, 값
        String topic = "my-topic";
        String key = "my-key";
        String message = "Hello, Kafka!";
        int partition = 0; // 전송할 파티션 번호

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, partition, key, message);
```

#### 커스텀 파티셔너 지정

비지니스 로직을 적용할 수 있는 커스텀 파티셔너를 사용하기 위해서는 `org.apache.kafka.clients.producer.Partitioner` 인터페이스를 구현해야 합니다. 이 인터페이스는 `partition()` 메서드를 구현해야 하며, 해당 메서드에서 커스텀 파티셔닝 로직을 작성합니다.

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.List;
import java.util.Map;
import java.util.Properties;

public class KafkaProducerExample {

    public static void main(String[] args) {
        // Kafka 클러스터의 브로커 목록
        String bootstrapServers = "localhost:9092";

        // 프로듀서 설정
        Properties properties = new Properties();
        properties.put("bootstrap.servers", bootstrapServers);
        properties.put("key.serializer", StringSerializer.class.getName());
        properties.put("value.serializer", StringSerializer.class.getName());
        properties.put("partitioner.class", CustomPartitioner.class.getName()); // 커스텀 파티셔너 설정

        // 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽, 키, 값
        String topic = "my-topic";
        String key = "my-key";
        String message = "Hello, Kafka!";

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, message);

        // 메시지 전송
        producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    System.out.println("메시지 전송 실패: " + exception.getMessage());
                } else {
                    System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
                }
            }
        });

        // 프로듀서 종료
        producer.close();
    }

    // 커스텀 파티셔너 클래스 구현
    public static class CustomPartitioner implements Partitioner {

        @Override
        public void configure(Map<String, ?> configs) {
            // 파티셔너 초기화 작업이 필요한 경우에 구현
        }

        @Override
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
            // 커스텀 파티셔닝 로직을 구현하여 파티션 번호를 결정
            List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
            int numPartitions = partitions.size();
            
            // 예시로 간단히 key의 길이로 파티션을 결정하는 로직을 구현
            int keyLength = ((String) key).length();
            return keyLength % numPartitions;
        }

        @Override
        public void close() {
            // 파티셔너 종료 작업이 필요한 경우에 구현
        }
    }
}

```

### 응답 정상 확인 (RecordMetadata)

`producer.send().get()` 메서드를 사용하여 `RecordMetadata`를 동기적으로 반환받는 방법은 `send()` 메서드가 완료될 때까지 현재 스레드를 차단(block)하는 방식입니다. 반면에 `Callback`을 이용한 방법은 비동기적으로 메시지를 전송하고 나중에 콜백 메서드가 호출되어 응답을 처리하는 방식입니다.

아래는 `Callback`을 사용한 코드와 `send().get()`을 사용한 코드 간의 차이점을 설명합니다.

**Callback을 사용한 방식:**

```java
producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            System.out.println("메시지 전송 실패: " + exception.getMessage());
        } else {
            System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
        }
    }
});
```

**send().get()을 사용한 방식:**

```java
try {
    RecordMetadata metadata = producer.send(record).get();
    System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
} catch (InterruptedException | ExecutionException e) {
    System.out.println("메시지 전송 실패: " + e.getMessage());
}
```

주요 차이점

1. **동기 vs 비동기**: `send().get()`은 메시지를 전송하고 응답을 기다릴 때 현재 스레드를 차단하여 동기적으로 처리합니다. 반면에 `Callback`은 비동기적으로 메시지를 전송하고 응답을 처리합니다. 비동기 방식은 메시지 전송 작업을 차단하지 않고 다른 작업을 동시에 수행할 수 있습니다.
2. **차단(blocking) vs 비차단(non-blocking)**: `send().get()`은 `get()` 메서드가 호출될 때까지 현재 스레드를 차단합니다. 이는 메시지 전송이 완료될 때까지 대기하지만, 다른 작업을 수행할 수 없습니다. `Callback`은 비동기적으로 동작하므로 차단하지 않고 메시지 전송 작업이 백그라운드에서 진행되는 동안 다른 작업을 수행할 수 있습니다.
3. **예외 처리**: `send().get()`은 `InterruptedException`과 `ExecutionException`을 처리해야 합니다. `send().get()` 메서드가 실행 중 예외가 발생하면 `ExecutionException`이 발생하고, `get()` 메서드 호출이 중지되면 `InterruptedException`이 발생할 수 있습니다. 이에 대한 예외 처리가 필요합니다. 반면에 `Callback`은 예외 처리를 명시적으로 수행할 필요가 없습니다. 예외는 콜백 메서드의 `Exception` 매개변수를 통해 전달되므로 적절한 예외 처리를 할 수 있습니다.

따라서, `Callback`을 사용하는 방식은 비동기적인 메시지 전송을 지원하고, 다른 작업을 동시에 수행할 수 있으며, 예외 처리도 쉽게 할 수 있습니다. 하지만 코드의 복잡성이 증가할 수 있습니다. `send().get()`을 사용하는 방식은 동기적인 처리와 예외 처리가 간단하며, 메시지 전송의 결과를 동기적으로 받을 수 있습니다. 그러나 차단(block)되어 다른 작업을 수행할 수 없으며, 코드의 유연성이 제한될 수 있습니다. 따라서 사용 목적에 맞게 적절한 방식을 선택해야 합니다.



## 컨슈머 App

### 알아두기

- 컨슈머는 한개의 파티션을 구독할 수 있다. 파티션은 여러개의 컨슈머에게 연결될 수 있다. 하지만 관리의 효율성을 위해 보통 `1개 파티션 <-> 1개 컨슈머` 방식으로 연결한다.
  목적에 따라 다양한 저장소에 데이터를 보내기 위해 여러 컨슈머를 채택할 수 있다.

- `파티션-컨슈머` 관계를 바꾸는것을 리밸런싱이라고 한다. 리밸런싱은 직접 할 수 있으며, 장애 상황에 발동하도록 할 수 있다.
- 



## 멱등성 프로듀서



## 스트림즈



## 커넥트



## 아키텍처