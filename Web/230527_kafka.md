## 카프카 기본 개념

### 카프카 내부 구조

![img](https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F6434aedf-f349-4cc1-800d-77c8e642eab9%2Fimage.png)

- 프로듀서: 데이터 파티션 내부 큐로 전송시킨다.
- 컨슈머: 파티션 내부 큐에서 데이터를 가져간다.
- 파티션: 데이터가 큐의 형태로 저장된다.
- 브로커: 컨트롤러 역할 및 데이터 저장/삭제를 수행한다.

### 카프카 예시로 이해하기

물류 배송 서비스를 예시로 들어보겠습니다.

1. Producer (생산자): 생산자는 물류 배송 서비스에서 배송 요청을 생성하는 주체입니다. 예를 들어, 고객이 배송을 요청하면 생산자는 해당 요청을 Kafka에 전송하여 배송 요청 메시지를 생성합니다. 이 배송 요청 메시지는 특정 토픽에 게시됩니다.
2. Broker (브로커): Kafka의 브로커는 메시지를 저장하고 처리하는 중앙 메시징 시스템입니다. 브로커는 Kafka 클러스터의 구성원으로, 메시지를 효율적으로 분산 저장하고 컨슈머에게 전달합니다. 예를 들어, 물류 배송 서비스에서 Kafka 브로커는 배송 요청 메시지를 받아서 적절한 토픽에 저장하고, 컨슈머 그룹에 속한 컨슈머들에게 메시지를 전달합니다.
3. Topic (토픽): 토픽은 Kafka에서 메시지의 카테고리를 나타내는 개념입니다. 물류 배송 서비스에서는 예를 들어 "delivery-requests"라는 토픽을 생성할 수 있습니다. 배송 요청 메시지는 이 토픽에 발행(publish)되어 저장되고, 해당 토픽을 구독(subscribe)하는 컨슈머 그룹에 전달됩니다.
4. Consumer Group (컨슈머 그룹): 컨슈머 그룹은 동일한 논리적 그룹에 속하는 컨슈머들의 모음입니다. 물류 배송 서비스에서 컨슈머 그룹은 배송 요청 메시지를 소비하는 로직을 실행하는 컨슈머들의 집합입니다. 컨슈머 그룹은 동일한 토픽을 구독하여 메시지를 분산 처리합니다. 예를 들어, "delivery-processing"이라는 컨슈머 그룹이 있을 수 있고, 이 그룹에 속한 컨슈머들은 "delivery-requests" 토픽의 메시지를 소비하여 배송 처리를 수행합니다. 컨슈머 그룹은 자동으로 파티션 할당 및 리밸런스를 관리하여 고가용성과 확장성을 제공합니다.



### 카프카 사용의 장단점

카프카는 파이프라인으로 아래 장점을 가진다.

1. 확장성: 카프카는 수평적으로 확장 가능한 아키텍처를 제공하여 대규모 데이터 처리를 지원합니다. 분산된 클러스터를 구성하여 많은 양의 데이터를 처리하고 고성능을 유지할 수 있습니다.
2. 고가용성: 카프카는 데이터 손실을 최소화하기 위해 내구성과 복구 기능을 제공합니다. 데이터는 여러 브로커에 복제되며, 하나의 브로커가 고장나더라도 데이터의 안정성과 가용성이 유지됩니다.
3. 실시간 데이터 스트리밍: 카프카는 실시간 데이터 스트리밍을 지원하기 위해 설계되었습니다. 데이터는 실시간으로 처리되고, 다양한 응용 프로그램에서 실시간으로 데이터를 소비할 수 있습니다. 이는 빠른 응답 시간이 필요한 분석, 모니터링 및 대시보드 작업에 매우 유용합니다.
4. 다양한 데이터 소스 및 대상과의 통합: 카프카는 다양한 데이터 소스 및 대상과의 통합을 지원합니다. 대규모 데이터 스트림을 제공하며, 다양한 시스템 및 플랫폼 간에 데이터를 신속하게 전송할 수 있습니다.
5. 유연성과 확장성: 카프카는 다양한 소비자 그룹을 지원하여 여러 응용 프로그램이 동시에 데이터를 처리하고 소비할 수 있습니다. 데이터를 여러 처리 파이프라인에 전달할 수 있으며, 데이터 소비자의 수를 동적으로 조정하여 시스템의 유연성과 확장성을 높일 수 있습니다.
6. 생태계 및 커뮤니티: 카프카는 활발한 개발자 커뮤니티와 다양한 플러그인, 도구, 라이브러리, 프레임워크 등의 풍부한 생태계를 가지고 있습니다. 이는 빅데이터 파이프라인을 구축하고 운영하는 데 많은 지원을 제공하며, 사용자들 간의 정보 공유와 협력을 촉진합니다.

단점으로는 아래와 같다.

1. 학습 곡선과 복잡성: 카프카는 초보자에게는 학습 곡선이 높을 수 있습니다. 초기 설정 및 구성, 클러스터 관리 등의 작업은 상당한 복잡성을 가질 수 있으며, 관리 및 운영에 대한 전문 지식이 필요할 수 있습니다.
2. 추가적인 인프라 비용: 카프카를 사용하기 위해서는 클러스터를 구성해야하며, 이는 추가적인 인프라 비용을 발생시킬 수 있습니다. 클러스터 구성, 유지 보수 및 확장에 대한 리소스가 필요합니다.
3. 데이터 관리: 카프카는 데이터를 영구적으로 저장하지 않습니다. 따라서, 데이터의 유지 기간이나 데이터 관리 정책에 따라 데이터를 처리하거나 외부 저장소로 이동시켜야 할 수 있습니다.
4. 복제 지연: 카프카는 데이터를 여러 브로커에 복제하여 내고장성을 보장합니다. 하지만, 데이터의 복제 과정에서 약간의 지연이 발생할 수 있습니다. 따라서, 실시간 데이터 처리가 중요한 경우에는 이를 고려해야 합니다.
5. 운영 및 모니터링 복잡성: 큰 규모의 카프카 클러스터를 운영하고 모니터링하는 것은 복잡할 수 있습니다. 클러스터의 건강 상태, 처리량, 지연 등을 모니터링하고 성능 이슈를 해결하기 위해 추가적인 노력과 도구가 필요할 수 있습니다.



### 카프카 초기 구동

1. Kafka 클러스터 시작: Kafka 클러스터는 여러 개의 브로커로 구성되어 있으며, 이들을 실행시켜야 합니다. 각 브로커는 `server.properties`와 같은 설정 파일을 기반으로 실행됩니다. 브로커를 실행하기 위해서는 ZooKeeper 서버가 먼저 실행되어야 하며, ZooKeeper 서버는 ZooKeeper 구성 파일인 `zookeeper.properties`를 사용하여 실행됩니다.
2. 토픽 생성: Kafka에 데이터를 저장할 토픽을 생성해야 합니다. 토픽 생성은 `kafka-topics.sh` 또는 `kafka-topics.bat`와 같은 Kafka 명령어를 사용하여 수행할 수 있습니다. 토픽 생성에는 토픽의 이름, 파티션 수, 복제본 수 등을 지정해야 합니다.
3. Producer 실행: 데이터를 생성하여 Kafka 클러스터로 전송할 Producer 애플리케이션을 실행합니다. Producer는 Kafka 클라이언트 라이브러리를 사용하여 작성되며, 필요한 설정과 연결 정보를 지정해야 합니다. Producer는 Kafka 클러스터에 데이터를 전송합니다.
4. Consumer 실행: Kafka 클러스터에서 데이터를 읽어오고 처리할 Consumer 애플리케이션을 실행합니다. Consumer 역시 Kafka 클라이언트 라이브러리를 사용하여 작성되며, 필요한 설정과 연결 정보를 지정해야 합니다. Consumer는 특정 토픽에서 데이터를 읽고 처리하는 로직을 포함하고 있습니다.
5. 데이터 처리: Consumer는 읽어온 데이터를 처리하는 로직을 구현해야 합니다. 이는 애플리케이션의 요구사항에 따라 달라집니다. 데이터 처리는 Consumer의 비즈니스 로직에 따라 이루어지며, 읽어온 데이터를 분석, 가공, 저장 등의 작업을 수행할 수 있습니다.



### 카프카 정상 동작 상황

1. 토픽(Topic) 생성: Kafka 클러스터에는 데이터를 저장하기 위한 토픽이 미리 생성되어 있어야 합니다. 토픽은 Producer가 데이터를 보내는 곳이며, Consumer가 데이터를 읽는 곳입니다.
2. Producer 등록: 애플리케이션에서 데이터를 생성하고 Kafka에 전송할 Producer를 등록합니다. Producer는 토픽에 대한 메시지를 생성하여 Kafka 클러스터로 보낼 수 있는 클라이언트입니다. Producer는 Kafka 브로커와 직접 통신하여 데이터를 보낼 수 있습니다.
3. Consumer 등록: 데이터를 읽어오기 위해 Consumer를 등록합니다. Consumer는 특정 토픽에서 데이터를 소비하고, 처리하는 클라이언트입니다. 여러 Consumer 그룹이 동시에 동일한 토픽을 읽을 수 있으며, 각 Consumer 그룹은 토픽의 파티션(Partition)에 대한 오프셋(Offset)을 관리합니다.
4. 데이터 생성 및 전송: Producer는 애플리케이션에서 데이터를 생성하고 Kafka 클러스터로 전송합니다. 데이터는 토픽에 대한 메시지로 패킹되며, 메시지는 Key-Value 형태로 구성될 수 있습니다. Producer는 토픽의 파티션을 직접 선택하거나, 메시지 Key의 해싱을 통해 파티션을 자동으로 선택할 수 있습니다.
5. 메시지 저장: Kafka 브로커는 수신한 메시지를 해당 토픽의 파티션에 저장합니다. 메시지는 토픽 내에서 파티션에 순서대로 추가됩니다. 파티션은 메시지의 순서를 보장하며, 각 파티션은 여러 개의 복제본(Replica)을 가질 수 있습니다.
6. Consumer 데이터 읽기: Consumer는 등록된 토픽의 파티션에서 데이터를 읽기 시작합니다. 각 Consumer 그룹은 파티션에 대한 오프셋을 추적하고, 아직 읽지 않은 메시지를 읽어오기 위해 오프셋을 조정합니다.
7. 데이터 처리: Consumer는 읽어온 데이터를 처리하고, 필요에 따라 애플리케이션에서 추가적인 작업을 수행합니다. 데이터 처리는 사용자 정의 로직에 따라 이루어집니다.
8. 커밋(Commit): Consumer 그룹은 처리한 메시지에 대한 오프셋을 커밋하여 Kafka에게 해당 오프셋을 알립니다. 이를 통해 Consumer 그룹은 다음에 다시 시작될 때 처리해야 할 오프셋을 추적하고 중복 처리를 방지할 수 있습니다.
9. 데이터 소비: Consumer 그룹이 오프셋을 커밋하면, 해당 오프셋 이후의 메시지들을 읽기 시작합니다. 이를 통해 데이터가 Consumer에게 전달되고 처리됩니다.



### 카프카 장애 상황

Kafka 클러스터에서 하나의 브로커 서버가 죽었을 때, 다음과 같은 일이 발생합니다. 아래는 순서대로 설명된 단계입니다:

1. 장애 감지: 클러스터의 다른 브로커나 모니터링 시스템은 브로커의 상태를 감지하고, 해당 브로커가 죽었다는 것을 인지합니다. 이는 네트워크 연결 끊김, 하트비트(Heartbeat) 손실 등의 방법을 통해 확인될 수 있습니다.
   - 하트비트(Heartbeat): 각 브로커는 일정한 주기로 주키퍼에게 하트비트 신호를 보냅니다. 하트비트는 브로커가 활성 상태임을 나타내며, 주키퍼는 이를 받아 브로커의 상태를 감지합니다.
   - 세션 타임아웃(Session Timeout): 브로커는 주키퍼에게 하트비트를 보내는 동안에도 정기적으로 세션 타임아웃 값을 재설정합니다. 만약 브로커가 정상적인 동작을 하지 않거나 연결이 끊어진 경우, 세션 타임아웃이 경과하면 주키퍼는 해당 브로커의 상태를 변경하여 장애로 판단합니다.
   - 주키퍼 감시: 주키퍼는 클러스터의 브로커들과 연결되어 상태를 감시합니다. 만약 주키퍼가 특정 브로커로부터 하트비트 신호를 받지 못하거나 세션 타임아웃이 발생한 경우, 해당 브로커의 상태를 비활성화된 상태로 판단하고, 클러스터에서 제거할 수 있습니다.
   - 리더 파티션 실패 감지: 주키퍼는 리더 파티션의 상태를 모니터링하고, 리더 파티션에 장애가 발생한 경우에는 해당 파티션의 리더를 재할당하는 작업을 수행합니다.
2. 리더 파티션 재할당: 죽은 브로커가 리더로 할당된 파티션들이 있을 경우, 클러스터 내의 다른 브로커들은 해당 파티션들에 대한 리더 역할을 다른 유효한 브로커로 재할당합니다. 이를 통해 데이터의 가용성과 내결함성을 유지할 수 있습니다.
3. ISR(In-Sync Replicas) 업데이트: ISR은 리더와 동기화된 복제본을 나타내는 집합입니다. 죽은 브로커가 ISR에 속한 복제본을 가지고 있었다면, 해당 복제본은 ISR에서 제외됩니다. 이는 클러스터의 데이터 복제를 유지하면서 죽은 브로커에 의존하지 않도록 합니다.
4. 프로듀서와 컨슈머의 재연결: 죽은 브로커와 연결되어 있던 프로듀서와 컨슈머는 해당 브로커와의 연결이 끊겼다는 것을 인지하고, 재연결을 시도합니다. 이 때, 주키퍼와의 상호작용을 통해 업데이트된 메타데이터를 얻어와 새로운 리더 파티션 정보를 알아냅니다.
   - 연결 끊김 감지: 프로듀서와 컨슈머는 주기적으로 브로커와의 연결 상태를 확인합니다. 만약 브로커와의 연결이 끊어진 것을 감지하면, 장애 상황으로 판단하고 재연결을 시도합니다.
   - 주키퍼와의 상호작용: 프로듀서와 컨슈머는 주키퍼에게 메타데이터를 조회하고 업데이트된 정보를 얻기 위해 상호작용합니다. 장애 상황에서는 주키퍼를 통해 새로운 메타데이터를 얻어옵니다. 이는 새로운 파티션 할당 정보, 리더 파티션 정보 등을 포함합니다.
   - 브로커 재연결: 프로듀서와 컨슈머는 업데이트된 메타데이터를 바탕으로 새로운 브로커와의 연결을 시도합니다. 이때, 장애로 인해 이전에 연결되었던 브로커와는 다른 브로커에 연결될 수 있습니다.
   - 메시지 처리 재개: 재연결에 성공한 프로듀서는 새로운 브로커에게 데이터를 전송하고, 컨슈머는 새로운 브로커에서 데이터를 읽어옵니다. 장애로 인해 발생한 메시지 손실을 최소화하기 위해 컨슈머는 재연결 후에 중단된 오프셋(Offset)에서부터 메시지 처리를 재개합니다.
5. 브로커 복구: 죽은 브로커가 복구되거나 대체 브로커가 새로 추가되면, 해당 브로커는 클러스터에 다시 참여하고 파티션의 리더 또는 복제본 역할을 맡을 수 있습니다.

### SaaS가 아닌 오픈소스만으로 사용 시 고려할 점

1. 하드웨어 요구 사항: Kafka는 대량의 데이터를 처리하기 때문에 충분한 처리 능력과 저장 공간이 필요합니다. 클러스터의 크기와 예상 데이터 스트림의 양에 맞게 서버 하드웨어를 선택해야 합니다.
2. 네트워크 구성: Kafka 클러스터는 고성능 및 안정적인 네트워크 연결을 필요로 합니다. 빠른 데이터 전송을 위해 클라이언트와 브로커 사이의 네트워크 대역폭과 지연 시간을 고려해야 합니다.
3. 데이터 백업 및 복구: Kafka는 데이터의 내구성을 보장하기 위해 복제 및 복구 메커니즘을 제공합니다. 데이터를 안전하게 보호하고 장애 복구를 위한 백업 및 복구 전략을 수립해야 합니다.
4. 보안: Kafka에는 데이터 흐름을 보호하기 위한 보안 기능이 포함되어 있습니다. SSL/TLS를 사용하여 네트워크 통신을 암호화하고, 클라이언트 인증 및 접근 제어를 설정하여 데이터의 기밀성과 무결성을 유지해야 합니다.
5. 클러스터 구성 및 모니터링: Kafka 클러스터는 여러 브로커로 구성되며, 이들을 적절하게 구성하고 관리해야 합니다. 클러스터의 상태와 성능을 모니터링하고, 필요한 경우 스케일링 및 리밸런싱을 수행하여 최적의 성능을 유지할 수 있도록 해야 합니다.
   - Broker 상태: Kafka 클러스터의 브로커 상태를 모니터링해야 합니다. 브로커의 가용성, 처리량, CPU 및 메모리 사용량, 디스크 사용량 등을 확인하여 잠재적인 문제를 식별하고 대응할 수 있습니다.
   - Topic 및 Partition 상태: Kafka는 Topic과 Partition으로 데이터를 구성합니다. 각 Topic과 Partition의 상태를 모니터링하여 데이터 유실, 복제 지연, 특정 Partition의 부하 집중 등의 문제를 감지할 수 있습니다.
   - Producer 및 Consumer 상태: Kafka Producer 및 Consumer의 상태를 모니터링하여 데이터 흐름에 문제가 발생하는지 확인할 수 있습니다. Producer의 전송률, 에러율, Consumer의 읽기 속도, 오프셋 커밋 상태 등을 모니터링해야 합니다.
   - Network 상태: Kafka는 네트워크를 통해 데이터를 전송합니다. 네트워크 대역폭, 지연 시간, 패킷 손실 등과 같은 네트워크 지표를 모니터링하여 데이터 전송 성능에 영향을 미치는 문제를 식별할 수 있습니다.
   - 리밸런싱 상태: Kafka 클러스터는 브로커 추가 또는 삭제, Topic 구성 변경 등의 이벤트에 따라 리밸런싱이 발생할 수 있습니다. 리밸런싱 상태를 모니터링하여 클러스터의 안정성과 데이터 분배가 올바르게 유지되는지 확인해야 합니다.
   - 지연 및 지표 추이: Kafka 클러스터의 지연 시간, 처리량, 에러율 등의 지표를 추적하여 시간 경과에 따른 성능 변화를 분석할 수 있습니다. 이를 통해 예측 및 용량 계획을 수립하고 성능 개선을 위한 조치를 취할 수 있습니다.
   - 로그 및 경고: Kafka 로그와 모니터링 도구에서 제공하는 경고를 확인하여 잠재적인 문제를 탐지할 수 있습니다. 로그 분석 및 경고 설정을 통해 프로덕션 환경에서 발생하는 이상 상황을 조기에 감지하고 대응할 수 있습니다.
6. 운영 및 유지보수: Kafka 클러스터의 운영과 유지보수는 주기적인 작업을 필요로 합니다. 메시지 보존 정책 설정, 로그 파일 관리, 시스템 패치 및 업그레이드 등의 작업을 계획하고 수행해야 합니다.
7. 커뮤니티 지원: Kafka는 활발한 개발자 커뮤니티와 오픈소스 생태계를 가지고 있습니다. 문제 발생 시 온라인 포럼, 메일링 리스트, 블로그 등에서 지원을 받을 수 있으며, 이러한 자원들을 활용하여 문제 해결과 최적화를 도모할 수 있습니다.





## 카프카 클러스터

### 클러스터에 속한것

Kafka 클러스터는 Apache Kafka 시스템을 구성하는 여러 개의 브로커로 구성된 분산 시스템입니다. 각각의 브로커는 고성능의 메시지 브로커 역할을 수행하며, 데이터의 안정적이고 신속한 전달을 위해 메시지를 저장하고 전송합니다.

Kafka 클러스터의 주요 구성 요소는 다음과 같습니다:

1. **브로커 (Broker)**: Kafka 클러스터의 기본 단위로, 메시지를 저장하고 전달하는 서버입니다. 여러 개의 브로커로 구성되며, 각 브로커는 고유한 ID를 가지고 있습니다. 브로커는 데이터를 토픽 단위로 파티션에 분산 저장하고, 클러스터 내의 다른 브로커들과 통신하여 데이터를 복제합니다.
2. **토픽 (Topic)**: Kafka에서 데이터를 주고받는 주요 단위입니다. 토픽은 메시지의 유사한 카테고리 또는 주제를 나타내며, 사용자가 정의할 수 있습니다. 각 토픽은 여러 개의 파티션으로 나누어질 수 있습니다.
3. **파티션 (Partition)**: 토픽은 파티션으로 나뉘어지며, 각 파티션은 순서가 있는 메시지의 일련을 나타냅니다. 파티션은 브로커들 사이에 분산되어 저장되며, 데이터의 처리량과 확장성을 높이는 역할을 합니다.
4. **리플리카 (Replica)**: 파티션은 여러 개의 리플리카로 구성될 수 있습니다. 각 리플리카는 동일한 파티션의 데이터의 복사본을 나타냅니다. 리플리카는 데이터의 내구성과 고가용성을 보장하기 위해 사용됩니다.
5. **프로듀서 (Producer)**: Kafka에 데이터를 생성하여 토픽으로 전송하는 클라이언트 애플리케이션입니다. 프로듀서는 메시지를 특정 토픽에 보내고, 필요한 경우 파티션 및 오프셋을 지정할 수 있습니다.
6. **컨슈머 (Consumer)**: Kafka에서 데이터를 소비하는 클라이언트 애플리케이션입니다. 컨슈머는 특정 토픽에서 메시지를 읽고 처리합니다. 여러 개의 컨슈머 그룹을 구성하여 동시에 데이터를 처리할 수 있습니다.

Kafka 클러스터는 대량의 데이터를 처리하고, 데이터의 안정적인 전달과 복제를 보장하기 위해 분산 아키텍처를 사용합니다. 브로커들은 자체적으로 클러스터의 메타데이터와 상태를 관리하며, 클러스터의 신뢰성과 확장성을 제공합니다.

### 클러스터가 아닌것

Kafka를 운영하기 위한 아키텍처에서 Kafka 클러스터에 직접적으로 속하지 않는 구성 요소는 다음과 같습니다:

1. **ZooKeeper**: Kafka 클러스터의 구성 관리와 리더 선출을 담당하는 분산 코디네이터인 ZooKeeper는 Kafka 클러스터에 속하지 않습니다. 그러나 Kafka 클러스터는 ZooKeeper를 의존하여 메타데이터와 상태 정보를 관리하고, 브로커들 간의 조정을 수행합니다.
2. **Producer**: Kafka 프로듀서는 Kafka 클러스터의 외부에 위치한 애플리케이션 또는 서비스입니다. 프로듀서는 Kafka 브로커로 데이터를 생성하고 전송합니다. Kafka 클러스터의 일부가 아니며, 데이터를 생성하고 전송하는 역할을 수행합니다.
3. **Consumer**: Kafka 컨슈머도 Kafka 클러스터의 외부에 위치한 애플리케이션 또는 서비스입니다. 컨슈머는 Kafka 토픽에서 데이터를 소비하고 처리합니다. Kafka 클러스터의 일부가 아니며, 데이터를 소비하고 처리하는 역할을 수행합니다.
4. **Kafka Connect**: Kafka Connect는 데이터 소스와 Kafka 클러스터를 연결해주는 분산 데이터 통합 프레임워크입니다. Kafka Connect는 Kafka 클러스터와 독립적으로 실행되며, 다양한 소스 및 대상 시스템과의 데이터 이동을 관리합니다.
5. **Kafka Streams**: Kafka Streams는 스트리밍 애플리케이션을 구축하기 위한 클라이언트 라이브러리입니다. Kafka Streams 애플리케이션은 Kafka 클러스터와 독립적으로 실행되며, 스트리밍 데이터 처리를 위한 기능을 제공합니다.

이러한 구성 요소들은 Kafka 클러스터와 상호 작용하며, Kafka에서 데이터를 생성, 전송, 소비 및 처리하기 위해 필요한 역할을 수행합니다. 그러나 직접적으로 Kafka 클러스터에 속하는 것은 아니며, 독립적으로 실행되거나 외부 시스템과의 상호 작용을 담당합니다.



## 카프카 CLI

카프카 설치: https://jyoondev.tistory.com/184

### 실행

```
#zookeeper 실행
bin/zookeeper-server-start.sh config/zookeeper.properties

#broker 실행
bin/kafka-server-start.sh config/server.properties

#topic 생성
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic hello.kafka

#(조건추가) topic 생성
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 10 --replication-factor 1 --topic hello.kafka2 --config retention.ms=172800000

```

### 확인

```
#broker 확인
bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092

#topic 확인
bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic hello.kafka --describe

#broker의 설정값 확인 
bin/kafka-configs.sh --bootstrap-server localhost:9092 --broker 0 --all --describe

```

### 변경

```
#topic partitions 증가 (hello.kafka를 10으로 증가)
bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic hello.kafka --alter --partitions 10

#topic 옵션 변경 (hello.kafka 변경)
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config min.insync.replicas=2 --topic hello.kafka

```

### 테스트

```
#Topic에 데이터 입력창 접속
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic hello.kafka

#(key 구분자 추가) Topic에 데이터 입력창 접속
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic hello.kafka --property "parse.key=true" --property "key.separator=:"

#Topic 내용 확인 (전체)
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic hello.kafka --from-beginning

```





## 프로듀서 App

### 알아두기

- 파티션 개수가 변경되는경우 동일키-파티션 매칭이 깨질 수 있다.

  

### 설정 옵션

#### 필수값

1. `bootstrap.servers`: 이 옵션은 Kafka 클러스터의 브로커 목록을 지정합니다. 프로듀서가 클러스터와 통신하기 위해 적어도 하나의 브로커 주소가 필요합니다.
2. `key.serializer`: 이 옵션은 프로듀서가 메시지 키를 직렬화하는 데 사용되는 직렬화 클래스를 지정합니다. 일반적으로 `org.apache.kafka.common.serialization.StringSerializer`와 같은 클래스를 사용하여 문자열 키를 직렬화합니다.
3. `value.serializer`: 이 옵션은 프로듀서가 메시지 값을 직렬화하는 데 사용되는 직렬화 클래스를 지정합니다. 마찬가지로, 일반적으로 `org.apache.kafka.common.serialization.StringSerializer`와 같은 클래스를 사용하여 문자열 값을 직렬화합니다.

#### 옵션값

1. `acks`: 이 옵션은 프로듀서가 메시지 전송을 성공으로 간주하기 위해 필요한 브로커의 확인 수를 지정합니다. 값으로 `all`, `1`, `0` 등을 설정할 수 있으며, 이는 각각 "모든 복제본이 확인을 해야 함", "최소한 한 개의 복제본이 확인을 해야 함(리더 파티션 확인하게 됨)", "확인을 기다리지 않음"을 의미합니다.

   일반적으로 1로 설정해서 운영하는 경우가 많다. 너무 높다면, 빠른 트래픽을 감당할 수 없다.

2. `compression.type`: 이 옵션은 프로듀서가 메시지를 압축하는 방법을 지정합니다. 압축을 사용하면 네트워크 대역폭을 절약할 수 있습니다. 일반적으로 `"none"`, `"gzip"`, `"snappy"`, `"lz4"`, `"zstd"`와 같은 압축 알고리즘을 지정할 수 있습니다.

3. `batch.size`: 이 옵션은 프로듀서가 단일 파티션에 대해 배치로 전송할 메시지 크기를 지정합니다. 메시지를 배치로 그룹화하여 대량 전송할 수 있으며, 이를 통해 네트워크 부하를 줄이고 전송 성능을 향상시킬 수 있습니다.

4. `linger.ms`: 이 옵션은 프로듀서가 배치를 전송하기 전에 대기하는 최대 시간을 지정합니다. 이를 통해 작은 메시지들을 모아서 큰 배치로 전송할 수 있으며, 효율성을 높일 수 있습니다.

5. `max.in.flight.requests.per.connection`: 이 옵션은 프로듀서가 동시에 브로커로 보낼 수 있는 요청의 최대 수를 제한합니다. 이를 통해 순서가 중요한 메시지를 제어하고, 프로듀서의 처리량을 조절할 수 있습니다.

6. `retries`: 이 옵션은 프로듀서가 메시지 전송 중에 실패한 경우 재시도할 횟수를 지정합니다. 이를 통해 네트워크 문제 또는 임시적인 오류로 인해 메시지가 손실되는 경우에도 안정성을 제공할 수 있습니다. 기본값은 2147483647이다. 안정성이 낮아도 된다면 0이나 작은수를 사용하면된다.

7. `max.block.ms`: 이 옵션은 프로듀서가 브로커에게 메시지를 보내지 못한 경우 대기할 최대 시간을 제어합니다. 이 값을 설정하면 메시지 전송이 불가능한 경우에도 프로듀서가 계속 실행되도록 조정할 수 있습니다.

8. `partitioner.class`: 이 옵션은 프로듀서가 메시지를 어떤 파티션에 보낼지 결정하는 파티셔너 클래스를 지정합니다. 기본적으로 파티셔너를 제공하지만, 사용자 정의 파티셔너를 구현하여 메시지 분배를 제어할 수도 있습니다.



### Java코드

#### 라이브러리

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>2.5.0</version>
    </dependency>
</dependencies>
```

#### 기본 코드

```java
import org.apache.kafka.clients.producer.*;

import java.util.Properties;

public class KafkaProducerExample {

    public static void main(String[] args) {
        // Kafka 클러스터의 브로커 목록
        String bootstrapServers = "localhost:9092";

        // 프로듀서 설정
        Properties properties = new Properties();
        properties.put("bootstrap.servers", bootstrapServers);
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽과 메시지
        String topic = "my-topic";
        String message = "Hello, Kafka!";

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, message);

        // 메시지 전송
        producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    System.out.println("메시지 전송 실패: " + exception.getMessage());
                } else {
                    System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
                }
            }
        });

        // 프로듀서 종료
        producer.close(); // flush 포함됨
    }
}

```

#### 메시지 키 추가

```java
		// 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽, 키, 메시지
        String topic = "my-topic";
        String key = "my-key";
        String message = "Hello, Kafka!";

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, message);
```

#### 파티션 번호 지정

```java
        // 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽, 키, 값
        String topic = "my-topic";
        String key = "my-key";
        String message = "Hello, Kafka!";
        int partition = 0; // 전송할 파티션 번호

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, partition, key, message);
```

#### 커스텀 파티셔너 지정

비지니스 로직을 적용할 수 있는 커스텀 파티셔너를 사용하기 위해서는 `org.apache.kafka.clients.producer.Partitioner` 인터페이스를 구현해야 합니다. 이 인터페이스는 `partition()` 메서드를 구현해야 하며, 해당 메서드에서 커스텀 파티셔닝 로직을 작성합니다.

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.List;
import java.util.Map;
import java.util.Properties;

public class KafkaProducerExample {

    public static void main(String[] args) {
        // Kafka 클러스터의 브로커 목록
        String bootstrapServers = "localhost:9092";

        // 프로듀서 설정
        Properties properties = new Properties();
        properties.put("bootstrap.servers", bootstrapServers);
        properties.put("key.serializer", StringSerializer.class.getName());
        properties.put("value.serializer", StringSerializer.class.getName());
        properties.put("partitioner.class", CustomPartitioner.class.getName()); // 커스텀 파티셔너 설정

        // 프로듀서 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        // 전송할 토픽, 키, 값
        String topic = "my-topic";
        String key = "my-key";
        String message = "Hello, Kafka!";

        // 메시지 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, message);

        // 메시지 전송
        producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    System.out.println("메시지 전송 실패: " + exception.getMessage());
                } else {
                    System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
                }
            }
        });

        // 프로듀서 종료
        producer.close();
    }

    // 커스텀 파티셔너 클래스 구현
    public static class CustomPartitioner implements Partitioner {

        @Override
        public void configure(Map<String, ?> configs) {
            // 파티셔너 초기화 작업이 필요한 경우에 구현
        }

        @Override
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
            // 커스텀 파티셔닝 로직을 구현하여 파티션 번호를 결정
            List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
            int numPartitions = partitions.size();
            
            // 예시로 간단히 key의 길이로 파티션을 결정하는 로직을 구현
            int keyLength = ((String) key).length();
            return keyLength % numPartitions;
        }

        @Override
        public void close() {
            // 파티셔너 종료 작업이 필요한 경우에 구현
        }
    }
}

```

### 응답 정상 확인 (RecordMetadata)

`producer.send().get()` 메서드를 사용하여 `RecordMetadata`를 동기적으로 반환받는 방법은 `send()` 메서드가 완료될 때까지 현재 스레드를 차단(block)하는 방식입니다. 반면에 `Callback`을 이용한 방법은 비동기적으로 메시지를 전송하고 나중에 콜백 메서드가 호출되어 응답을 처리하는 방식입니다.

아래는 `Callback`을 사용한 코드와 `send().get()`을 사용한 코드 간의 차이점을 설명합니다.

**Callback을 사용한 방식:**

```java
producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            System.out.println("메시지 전송 실패: " + exception.getMessage());
        } else {
            System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
        }
    }
});
```

**send().get()을 사용한 방식:**

```java
try {
    RecordMetadata metadata = producer.send(record).get();
    System.out.println("메시지 전송 성공. Offset: " + metadata.offset());
} catch (InterruptedException | ExecutionException e) {
    System.out.println("메시지 전송 실패: " + e.getMessage());
}
```

주요 차이점

1. **동기 vs 비동기**: `send().get()`은 메시지를 전송하고 응답을 기다릴 때 현재 스레드를 차단하여 동기적으로 처리합니다. 반면에 `Callback`은 비동기적으로 메시지를 전송하고 응답을 처리합니다. 비동기 방식은 메시지 전송 작업을 차단하지 않고 다른 작업을 동시에 수행할 수 있습니다.
2. **차단(blocking) vs 비차단(non-blocking)**: `send().get()`은 `get()` 메서드가 호출될 때까지 현재 스레드를 차단합니다. 이는 메시지 전송이 완료될 때까지 대기하지만, 다른 작업을 수행할 수 없습니다. `Callback`은 비동기적으로 동작하므로 차단하지 않고 메시지 전송 작업이 백그라운드에서 진행되는 동안 다른 작업을 수행할 수 있습니다.
3. **예외 처리**: `send().get()`은 `InterruptedException`과 `ExecutionException`을 처리해야 합니다. `send().get()` 메서드가 실행 중 예외가 발생하면 `ExecutionException`이 발생하고, `get()` 메서드 호출이 중지되면 `InterruptedException`이 발생할 수 있습니다. 이에 대한 예외 처리가 필요합니다. 반면에 `Callback`은 예외 처리를 명시적으로 수행할 필요가 없습니다. 예외는 콜백 메서드의 `Exception` 매개변수를 통해 전달되므로 적절한 예외 처리를 할 수 있습니다.

따라서, `Callback`을 사용하는 방식은 비동기적인 메시지 전송을 지원하고, 다른 작업을 동시에 수행할 수 있으며, 예외 처리도 쉽게 할 수 있습니다. 하지만 코드의 복잡성이 증가할 수 있습니다. `send().get()`을 사용하는 방식은 동기적인 처리와 예외 처리가 간단하며, 메시지 전송의 결과를 동기적으로 받을 수 있습니다. 그러나 차단(block)되어 다른 작업을 수행할 수 없으며, 코드의 유연성이 제한될 수 있습니다. 따라서 사용 목적에 맞게 적절한 방식을 선택해야 합니다.



## 컨슈머 App

### 알아두기

- 컨슈머는 한개의 파티션을 구독할 수 있다. 파티션은 여러개의 컨슈머에게 연결될 수 있다. 하지만 관리의 효율성을 위해 보통 `1개 파티션 <-> 1개 컨슈머` 방식으로 연결한다.
  목적에 따라 다양한 저장소에 데이터를 보내기 위해 여러 컨슈머를 채택할 수 있다.
- `파티션-컨슈머` 관계를 바꾸는것을 리밸런싱이라고 한다. 리밸런싱은 직접 할 수 있으며, 장애 상황에 발동하도록 할 수 있다.

### 설정 옵션

#### 필수값

1. `bootstrap.servers`: 이 옵션은 Kafka 브로커의 호스트와 포트 정보를 설정합니다. 컨슈머는 이 정보를 사용하여 브로커에 연결합니다. 여러 개의 브로커가 있는 경우 쉼표로 구분하여 여러 개의 서버를 지정할 수 있습니다.
2. `key.deserializer` 및 `value.deserializer`: 컨슈머가 메시지의 키와 값의 직렬화된 형식을 해독할 수 있도록 지정합니다. 예를 들어, 문자열 형식의 키와 JSON 형식의 값인 경우에는 각각 `StringDeserializer`와 `JsonDeserializer`를 사용할 수 있습니다.

#### 옵션값

1. `group.id`: 이 옵션은 컨슈머 그룹의 식별자를 설정합니다. 컨슈머 그룹은 동일한 토픽을 구독하는 여러 컨슈머들을 그룹화하여 메시지를 분산 소비할 수 있도록 합니다. subscribe() 메서드로 토픽을 구동할 시 **필수값**입니다.
2. `enable.auto.commit`: 이 옵션을 `true`로 설정하면 컨슈머가 자동으로 오프셋을 커밋하도록 할 수 있습니다. 이는 컨슈머의 읽기 위치를 기록하여 재시작할 때 마지막으로 읽은 위치부터 메시지를 소비할 수 있게 해줍니다. 기본값은 true입니다.
3. `auto.offset.reset`: 이 옵션은 컨슈머가 커밋된 오프셋이 없거나 오프셋이 유효하지 않은 경우 어떻게 처리할지를 설정합니다. "earliest"는 가장 이전의 오프셋부터, "latest"는 가장 최근의 오프셋부터, "none"은 기존 커밋 기록 이후 오프셋부터 읽기 시작한다. 보통 latest나 earliest로 설정하는것이 일반적이다.
4. `fetch.min.bytes` 및 `fetch.max.wait.ms`: 컨슈머가 메시지를 가져오는 동작을 제어합니다. `fetch.min.bytes`는 브로커에서 가져와야 하는 최소 데이터 양을 설정하고, `fetch.max.wait.ms`는 브로커로부터 응답을 기다리는 최대 대기 시간을 설정합니다. 이러한 옵션을 조정하여 메시지의 끊김과 대기 시간 간의 균형을 조정할 수 있습니다.
5. `max.poll.records`: 이 옵션은 단일 `poll()` 호출에서 반환할 수 있는 최대 레코드 수를 제한합니다. 이를 통해 한 번에 처리하는 레코드의 양을 제어할 수 있습니다.
6. `session.timeout.ms` 및 `heartbeat.interval.ms`: 컨슈머의 하트비트 메시지를 사용하여 컨슈머의 상태를 브로커에 보고하는 동작을 제어합니다. `session.timeout.ms`는 컨슈머가 하트비트를 보내지 않는 최대 시간을 설정하고, `heartbeat.interval.ms`는 하트비트를 보내는 간격을 설정합니다. 이를 통해 컨슈머의 활성 상태를 확인하고 장애 조건을 식별할 수 있습니다.
7. `auto.commit.interval.ms`: 이 옵션은 자동 커밋을 수행하는 간격을 설정합니다. `enable.auto.commit` 옵션이 `true`로 설정되어 있을 때 컨슈머가 오프셋을 자동으로 커밋하는 주기를 지정할 수 있습니다.
8. `max.partition.fetch.bytes`: 이 옵션은 단일 파티션에서 한 번에 가져올 수 있는 최대 데이터 양을 제한합니다. 이를 사용하여 더 작은 청크로 메시지를 가져올 수 있으며, 대량의 데이터를 처리할 때 유용합니다.

### Java코드

#### 라이브러리

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>2.5.0</version>
    </dependency>
</dependencies>

```

#### 기본코드

```java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.util.Collections;
import java.util.Properties;

public class KafkaConsumerExample {
    public static void main(String[] args) {
        // Kafka 브로커 호스트와 포트 설정
        String bootstrapServers = "localhost:9092";

        // 컨슈머 그룹 ID 설정
        String groupId = "my-consumer-group";

        // 토픽 설정
        String topic = "my-topic";

        // Kafka 컨슈머 설정
        Properties props = new Properties();
        props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        props.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
        props.setProperty(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");

        // Kafka 컨슈머 생성
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

        // 토픽 구독
        consumer.subscribe(Collections.singletonList(topic));

        // 메시지 소비 루프
        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(100); // 100ms 응답 대기

                for (ConsumerRecord<String, String> record : records) {
                    System.out.println("Received message: key = " + record.key() + ", value = " + record.value());
                }

                consumer.commitAsync();
            }
        } finally {
            consumer.close();
        }
    }
}
```

#### 커밋

`consumer.commitAsync()` 메서드는 컨슈머의 오프셋을 비동기적으로 커밋하는 역할을 합니다. 이 메서드는 현재 소비한 메시지의 오프셋을 커밋하여 컨슈머의 그룹 오프셋을 업데이트합니다. 이를 통해 컨슈머가 다음에 재시작될 때 마지막으로 소비한 위치부터 메시지를 다시 처리할 수 있게 됩니다.

`consumer.commitAsync()` 메서드는 비동기적으로 커밋이 이루어지기 때문에 메서드 호출 후 바로 반환됩니다. 커밋 결과에 대한 콜백을 처리할 수 있도록 `OffsetCommitCallback` 인터페이스를 구현하여 제공할 수도 있습니다. 이를 통해 커밋이 성공적으로 이루어졌는지 또는 실패했는지에 대한 알림을 받을 수 있습니다.

반면, `consumer.commitSync()` 메서드는 커밋을 동기적으로 수행합니다. 이 메서드는 커밋 결과가 반환될 때까지 블로킹되며, 커밋 작업이 완료될 때까지 대기합니다. 따라서 `commitSync()` 메서드는 메시지의 커밋에 대한 동기적인 보장을 제공합니다. 그러나 이로 인해 애플리케이션의 처리 속도가 저하될 수 있습니다.

비동기적인 `commitAsync()` 메서드를 사용하는 것은 일반적으로 더 높은 처리량과 빠른 응답성을 제공할 수 있습니다. 그러나 몇 가지 메시지의 손실 가능성이 존재할 수 있습니다. 동기적인 `commitSync()` 메서드는 메시지의 커밋을 보다 안전하게 보장하지만, 처리량과 응답성이 좀 더 낮을 수 있습니다. 어떤 방식을 선택할지는 어플리케이션의 요구사항과 메시지 처리의 중요도에 따라 결정해야 합니다.

```
consumer.commitAsync();
consumer.commitSync();
```

**AUTO_COMMIT 옵션과 commitAsync()를 둘 다 사용하는 이유는 무엇일까?**

`ENABLE_AUTO_COMMIT_CONFIG` 옵션을 `true`로 설정하면 컨슈머는 일정 간격으로 자동으로 오프셋을 커밋합니다. 하지만 `commitAsync()` 메서드를 추가적으로 호출하는 이유는 다음과 같습니다:

1. 제어된 커밋: `ENABLE_AUTO_COMMIT_CONFIG`를 `true`로 설정하면 컨슈머는 일정한 간격으로 자동으로 커밋을 수행하지만, 커밋 간격을 완전히 제어할 수 없습니다. 따라서 `commitAsync()`를 명시적으로 호출하여 메시지 처리 후 즉시 커밋을 수행할 수 있습니다. 이를 통해 더 정확한 제어를 할 수 있고, 메시지 처리 중간에 커밋되지 않은 상태로 장애가 발생하더라도 메시지의 중복 소비를 최소화할 수 있습니다.
2. 비동기 커밋: `commitAsync()` 메서드를 사용하면 커밋이 비동기적으로 수행됩니다. 이는 커밋 작업이 블로킹되지 않고 컨슈머가 다른 메시지를 처리하는 동안 커밋을 수행할 수 있다는 것을 의미합니다. 이는 컨슈머의 처리 속도를 향상시키고, 더 높은 처리량과 빠른 응답성을 제공할 수 있습니다.
3. 미처리 메시지 처리: `ENABLE_AUTO_COMMIT_CONFIG`가 `true`로 설정된 상태에서도 메시지 처리 중 예외가 발생하거나 컨슈머 장애가 발생할 수 있습니다. 이 경우에는 자동 커밋이 이루어지지 않으며, 처리되지 않은 메시지는 재처리해야 합니다. `commitAsync()` 메서드를 호출하여 처리 완료된 메시지의 오프셋을 명시적으로 커밋하면, 장애 복구 후에도 중복 처리를 방지하고 처리되지 않은 메시지를 정확하게 재처리할 수 있습니다.

따라서 `ENABLE_AUTO_COMMIT_CONFIG`를 `true`로 설정한 경우에도 `commitAsync()` 메서드를 추가적으로 호출하여 커밋을 수행하는 것은 메시지 처리의 정확성과 안정성을 보장하기 위해 권장되는 접근 방식입니다.

#### 안전 종료

`wakeup()` 메서드는 현재 실행 중인 `poll()` 메서드의 블로킹을 즉시 중단시키는 역할을 합니다. 일반적으로 컨슈머는 메시지를 소비하기 위해 `poll()` 메서드를 반복적으로 호출하며, 이때 `poll()` 메서드는 브로커로부터 메시지를 가져올 때까지 블로킹됩니다. `wakeup()` 메서드를 호출하면 `poll()` 메서드의 블로킹이 즉시 해제되고 `WakeupException`이 발생합니다. 이를 통해 컨슈머가 브로커로부터 메시지를 가져오는 작업을 중단하고 종료할 수 있습니다.

`close()` 메서드는 컨슈머를 종료하는 역할을 합니다. 이 메서드는 컨슈머가 사용 중인 리소스를 정리하고 브로커와의 연결을 종료합니다. `close()` 메서드는 호출되면 컨슈머는 더 이상 메시지를 소비하지 않으며 종료됩니다.

컨슈머를 안전하게 종료하기 위해서는 다음과 같은 절차를 따릅니다:

1. 컨슈머의 `poll()` 메서드가 실행 중인 상태에서 `wakeup()` 메서드를 호출하여 블로킹을 즉시 중단시킵니다.
2. `poll()` 메서드에서 발생한 `WakeupException`을 처리하여 종료를 처리합니다.
3. `close()` 메서드를 호출하여 컨슈머를 종료하고 사용 중인 리소스를 정리합니다.

이러한 절차를 따르면 컨슈머가 안전하게 종료되며, 중단된 상태에서도 안정적으로 메시지 처리를 완료할 수 있습니다.

apllication을 kill 할때는 `kill -15 PID`를 이용하는것이 좋습니다. 종료가 되지 않을 시 `-2` 옵션을 검토할 수 있습니다.

### 컨슈머 모니터링

#### 컨슈머 랙

Kafka의 컨슈머에서 "lag"는 컨슈머가 아직 처리하지 않은 메시지의 양을 나타내는 지표입니다. 간단히 말해, lag는 현재 컨슈머가 읽을 준비가 되어있는 메시지 중에서 아직 처리하지 않은 메시지의 수를 의미합니다.

**shell script를 통한 모니터링**

```bash
#!/bin/bash

bootstrap_servers="your_bootstrap_servers"
consumer_group_id="your_consumer_group_id"
topic_name="your_topic_name"
partition=0

while true; do
    lag_output=$(kafka-consumer-groups.sh --bootstrap-server $bootstrap_servers --group $consumer_group_id --describe | awk -v topic="$topic_name" -v partition=$partition '$1 == topic && $2 == partition {print $5}')
    lag=$(echo "$lag_output" | grep -oE '[0-9]+')

    echo "Current lag: $lag"

    sleep 5
done

```

이외에도 java 코드 기반에서 method를 통해 조회할 수 있다. 하지만, jvm에 종속된다는 문제 때문에 Datadog, Confluent Control Center, Burrow와 같은 외부 툴을 이용하는것이 더 추천된다.



## 멱등성, 트랜잭션 

### 카프카에서 멱등성 전략

Kafka 2.5 버전에서 멱등성을 보장하기 위해 다음과 같은 방법을 사용할 수 있습니다.

1. 메시지 키(Key) 활용: Kafka는 각각의 메시지에 고유한 키를 할당할 수 있습니다. 메시지 키는 동일한 키를 가지는 메시지가 항상 동일한 파티션으로 전달되도록 보장합니다. 따라서 동일한 키를 가진 메시지를 여러 번 발행하더라도 Kafka는 이를 중복으로 처리하지 않고 한 번만 처리합니다. 이를 통해 멱등성을 달성할 수 있습니다.
2. 컨슈머 오프셋(Consumer Offset) 관리: Kafka 컨슈머는 자체적으로 메시지 오프셋을 관리합니다. 오프셋은 컨슈머가 특정 토픽의 파티션에서 메시지를 소비하는 위치를 나타냅니다. 컨슈머는 메시지를 처리한 후에 오프셋을 커밋(commit)하여 처리한 메시지에 대한 정보를 저장합니다. 이를 통해 컨슈머는 중복 소비를 방지하고, 멱등성을 보장할 수 있습니다. Kafka에서는 자동 커밋 및 수동 커밋의 방식을 선택할 수 있으며, 적절한 설정과 커밋 전략을 사용하여 멱등성을 확보할 수 있습니다.
3. 메시지 처리 시스템 설계: 멱등성을 보장하기 위해 Kafka를 사용하는 메시지 처리 시스템은 일부 추가적인 설계 원칙을 고려해야 합니다. 예를 들어, 메시지 처리 시스템은 상태 변화에 무관하게 동작하도록 설계되어야 합니다. 이는 동일한 메시지를 여러 번 처리하더라도 동일한 결과를 보장합니다. 또한, 메시지 처리 시스템은 이벤트 기반 아키텍처를 활용하여 메시지의 순서와 의미를 보장하는 것이 중요합니다. 이를 통해 멱등성을 유지하면서도 정확한 메시지 처리를 수행할 수 있습니다.

멱등성은 메시지 처리 시스템에서 중요한 개념이며, Kafka는 메시지 키, 컨슈머 오프셋 관리 및 설계 원칙을 활용하여 멱등성을 보장할 수 있는 강력한 기능을 제공합니다.

#### Java코드

Producer

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class KafkaIdempotentProducerExample {

    private static final String TOPIC_NAME = "my_topic";
    private static final String BOOTSTRAP_SERVERS = "localhost:9092";

    public static void main(String[] args) {
        // Producer 설정
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true"); // 멱등성 활성화

        // Producer 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        // 메시지 발송
        for (int i = 0; i < 10; i++) {
            String key = "key_" + i;
            String value = "message_" + i;
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, key, value);
            producer.send(record, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception == null) {
                        System.out.println("메시지 전송 성공 - topic: " + metadata.topic() +
                                ", partition: " + metadata.partition() +
                                ", offset: " + metadata.offset());
                    } else {
                        System.out.println("메시지 전송 실패: " + exception.getMessage());
                    }
                }
            });
        }

        // Producer 종료
        producer.flush();
        producer.close();
    }
}
```

Consumer

```java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

public class KafkaIdempotentConsumerExample {

    private static final String TOPIC_NAME = "my_topic";
    private static final String GROUP_ID = "my_consumer_group";
    private static final String BOOTSTRAP_SERVERS = "localhost:9092";

    public static void main(String[] args) {
        // Consumer 설정
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest"); // 처음부터 메시지를 읽기 위해 earliest 설정

        // Consumer 생성
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

        // 토픽 구독
        consumer.subscribe(Collections.singletonList(TOPIC_NAME));

        // 메시지 소비
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println("메시지 수신 - topic: " + record.topic() +
                        ", partition: " + record.partition() +
                        ", offset: " + record.offset() +
                        ", key: " + record.key() +
                        ", value: " + record.value());
            }
        }
    }
}
```



### 트랜잭션


Kafka에서 트랜잭션을 다루기 위해 아래의 방법을 사용할 수 있습니다.

1. Producer에서 트랜잭션 사용:
   - `transactional.id` 프로퍼티를 Producer 설정에 추가하여 트랜잭션 ID를 지정합니다.
     프로듀서별로 고유한 ID를 사용해야하며 UUID가 많이 사용된다.
   - `enable.idempotence` 프로퍼티를 `true`로 설정하여 멱등성을 활성화합니다.
   - Producer가 트랜잭션을 시작하기 전에 `initTransactions()` 메서드를 호출하여 트랜잭션 초기화를 수행합니다.
   - 트랜잭션을 시작하기 위해 `beginTransaction()` 메서드를 호출합니다.
   - 트랜잭션 내에서 보낼 메시지를 `send()` 메서드를 사용하여 발행합니다.
   - 모든 메시지가 정상적으로 발행되면 `commitTransaction()` 메서드를 호출하여 트랜잭션을 커밋합니다. 실패한 경우 `abortTransaction()` 메서드를 호출하여 트랜잭션을 롤백할 수 있습니다.
2. Consumer에서 트랜잭션 사용:
   - `isolation.level` 프로퍼티를 Consumer 설정에 추가하여 트랜잭션의 분리 수준을 설정합니다. 'read_committed'로 커밋된 레코드만 읽을 수 있다.
   - `enable.auto.commit` 프로퍼티를 `false`로 설정하여 자동 커밋을 비활성화합니다.
   - 메시지를 처리한 후에 `commitSync()` 또는 `commitAsync()` 메서드를 호출하여 오프셋을 수동으로 커밋합니다.
   - 트랜잭션을 롤백해야 하는 경우, 메시지를 다시 처리하거나 처리하지 않고 오프셋을 롤백할 수 있습니다.
3. 트랜잭션 관리:
   - Kafka는 트랜잭션의 원자성(Atomicity)을 보장하기 위해 장애 상황에서도 데이터 일관성을 유지합니다. 예를 들어, Producer의 트랜잭션은 특정 파티션의 모든 메시지를 커밋하거나 롤백합니다.
   - 트랜잭션을 보다 잘 관리하기 위해 `isolation.level` 프로퍼티를 설정하여 Consumer의 트랜잭션 분리 수준을 조정할 수 있습니다.
   - `acks` 프로퍼티를 사용하여 Producer의 메시지 전송 확인 정책을 설정할 수 있습니다.



## 스트림즈

### 카프카 스트림즈 사용 케이스

1. 데이터 변환 및 강화: Kafka Streams는 데이터 스트림을 변환하고 강화하는 데 사용될 수 있습니다. 예를 들어, 입력 데이터를 가져와서 필요한 형식으로 변환하거나, 데이터를 정제하고 필터링하여 품질을 향상시킬 수 있습니다. 이를 통해 데이터를 다른 시스템으로 전송하기 전에 사전 처리 단계를 수행할 수 있습니다.
2. 이벤트 기반 아키텍처: Kafka Streams는 이벤트 기반 아키텍처에서 중요한 역할을 할 수 있습니다. 이벤트 스트림을 처리하고 여러 이벤트 소스를 조인하거나 집계하는 데 사용할 수 있습니다. 예를 들어, 여러 마이크로서비스에서 생성된 이벤트를 통합하고 분석하여 실시간으로 의사 결정을 내릴 수 있습니다.
3. 실시간 분석: Kafka Streams를 사용하여 실시간으로 데이터를 분석하고 결과를 생성할 수 있습니다. 예를 들어, 스트림 데이터에서 패턴을 감지하거나 실시간으로 집계를 수행하여 실시간 대시보드를 업데이트할 수 있습니다. 이를 통해 실시간으로 비즈니스 지표를 모니터링하고 실시간으로 행동을 취할 수 있습니다.
4. 데이터 파이프라인 구축: Kafka Streams는 데이터 파이프라인을 구축하는 데 사용될 수 있습니다. 데이터 소스에서 데이터를 가져와서 변환, 필터링, 집계 등의 작업을 수행한 후 다른 시스템으로 전송하는 등의 데이터 처리 과정을 구현할 수 있습니다. 이를 통해 데이터 흐름을 구조화하고 데이터 통합을 단순화할 수 있습니다.

### 스트림즈 데이터 추상화 개념

Kafka Streams에서 KStream, KTable 및 GlobalKTable은 데이터 처리를 위한 주요 추상화 개념입니다. 

1. KStream:
   - KStream은 연속적인 스트림 형태의 데이터를 나타냅니다. 데이터는 시간의 흐름에 따라 순차적으로 처리됩니다.
   - KStream은 변경 가능한 상태를 가지지 않으며, 메시지가 도착하면 일련의 연산을 수행하여 데이터를 변환하거나 분석합니다.
   - 데이터를 변환하고 필터링하는 등의 작업을 수행할 수 있으며, 다른 KStream 또는 KTable과 조인할 수도 있습니다.
2. KTable:
   - KTable은 변경 가능한 상태를 가지는 테이블 형태의 데이터를 나타냅니다. 키-값 쌍의 데이터를 관리하고, 각 키에 대한 최신 상태를 유지합니다.
   - KTable은 스트림 데이터의 키-값 매핑을 나타내며, 데이터의 업데이트 및 삭제 작업을 지원합니다.
   - KTable은 스트림 데이터에 대한 집계, 그룹화, 조인 등의 작업을 수행할 수 있습니다.
   - KTable은 변경 가능한 상태를 가지기 때문에 변경된 데이터를 조회할 수 있으며, 다른 KStream 또는 KTable과 조인할 수도 있습니다.
3. GlobalKTable:
   - GlobalKTable은 분산된 Kafka 토픽의 데이터를 지역 캐시화한 형태의 테이블입니다.
   - GlobalKTable은 모든 Kafka Streams 애플리케이션 인스턴스에서 공유되는 전역 테이블로서, 모든 인스턴스에서 동일한 뷰를 제공합니다.
   - 데이터를 조회할 때 토픽에서 데이터를 읽어서 지역 캐시에 저장하므로 데이터에 대한 접근이 빠릅니다.
   - 일반적으로 특정 키를 기반으로 데이터를 조회하고 조인하는 경우에 사용됩니다.

### 설정옵션

#### 필수값

1. Application ID (애플리케이션 식별자):
   - Kafka Streams 애플리케이션은 고유한 Application ID를 가져야 합니다. Application ID는 애플리케이션을 식별하는 데 사용되며, Kafka Streams 내부에서 토픽 이름을 생성하는 데에도 사용됩니다.
   - Application ID는 각각의 애플리케이션 인스턴스가 고유한 식별자를 가지도록 해야합니다.
2. Bootstrap Servers (부트스트랩 서버):
   - Kafka 클러스터와의 연결을 설정하기 위해 부트스트랩 서버를 지정해야 합니다. 부트스트랩 서버는 Kafka 클러스터의 최소 하나의 브로커 주소를 나타냅니다.
   - 애플리케이션은 부트스트랩 서버를 통해 Kafka 클러스터와 통신하고 토픽에 접근합니다.

#### 옵션값

1. Topology Optimization (토폴로지 최적화):
   - `StreamsConfig.TOPOLOGY_OPTIMIZATION`: 토폴로지 최적화 모드를 설정합니다. 기본값은 `"none"`이며, `"all"`로 설정하여 토폴로지 최적화를 활성화할 수 있습니다.
2. State Stores (상태 저장소):
   - `StreamsConfig.STATE_DIR`: 상태 저장소를 위한 디렉토리 경로를 설정합니다. 기본값은 `/tmp/kafka-streams`입니다.
   - `StreamsConfig.CACHE_MAX_BYTES_BUFFERING`: 상태 저장소의 최대 캐시 크기를 설정합니다. 기본값은 `10MB`입니다.
3. Windowing (윈도잉):
   - `StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS`: 윈도우 상태 저장소의 변경 로그 추가 보존 시간을 설정합니다. 기본값은 `1 day`입니다.
   - `StreamsConfig.COMMIT_INTERVAL_MS`: 커밋 간격을 설정합니다. 윈도우 처리 결과를 커밋하는 주기를 나타내며, 기본값은 `30 seconds`입니다.
4. Join Strategies (조인 전략):
   - `StreamsConfig.JOIN_WINDOW_MS`: 조인 작업에 사용되는 윈도우 크기를 설정합니다. 기본값은 `24 hours`입니다.
   - `StreamsConfig.JOIN_TOLERANCE_MS`: 조인 작업에서 허용되는 시간 허용 오차를 설정합니다. 기본값은 `0 milliseconds`입니다.
5. Error Handling (에러 처리):
   - `StreamsConfig.RETRIES`: 재시도 횟수를 설정합니다. 애플리케이션에서 에러가 발생했을 때 재시도하는 횟수를 나타내며, 기본값은 `0`입니다.
   - `StreamsConfig.ERROR_TOPIC_NAME`: 에러를 전송하는 데 사용되는 에러 토픽의 이름을 설정합니다. 기본값은 `"streams-error"`입니다.

### Java코드

#### 라이브러리

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-streams</artifactId>
        <version>2.5.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>2.5.0</version>
    </dependency>
</dependencies>
```

#### 기본코드

```java
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;

import java.util.Properties;

public class KafkaStreamsExample {
    public static void main(String[] args) {
        // Kafka Streams 애플리케이션 설정
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "kafka-streams-example");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        // StreamsBuilder 인스턴스 생성
        StreamsBuilder builder = new StreamsBuilder();

        // 입력 토픽을 읽고 데이터를 대문자로 변환하여 출력 토픽에 저장
        KStream<String, String> input = builder.stream("input-topic");
        KStream<String, String> uppercase = input.mapValues(String::toUpperCase);
        uppercase.to("output-topic"); // 특정 토픽에 저장

        // Kafka Streams 애플리케이션 실행
        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();

        // 애플리케이션 종료 시 Ctrl+C로 종료할 수 있도록 대기
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }
}
```

#### JOIN 예제 

```java
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.Joined;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;

import java.util.Properties;

public class KafkaStreamsJoinExample {
    public static void main(String[] args) {
        // Kafka Streams 애플리케이션 설정
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "kafka-streams-join-example");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        // StreamsBuilder 인스턴스 생성
        StreamsBuilder builder = new StreamsBuilder();

        // 첫 번째 입력 토픽을 KStream으로 읽기
        KStream<String, String> stream1 = builder.stream("input-topic-1");

        // 두 번째 입력 토픽을 KTable로 읽기
        KTable<String, String> table = builder.table("input-topic-2");

        // 조인 연산 수행
        KStream<String, String> joinedStream = stream1.join(
                table,
                (value1, value2) -> value1 + "-" + value2,
                Joined.with(Serdes.String(), Serdes.String(), Serdes.String())
        );

        // 결과를 출력 토픽에 저장
        joinedStream.to("output-topic", Produced.with(Serdes.String(), Serdes.String()));

        // Kafka Streams 애플리케이션 실행
        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();

        // 애플리케이션 종료 시 Ctrl+C로 종료할 수 있도록 대기
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }
}
```

#### Window Processing

Kafka Streams의 Window Processing은 시간 범위 내에서 데이터를 처리하는 기능을 말합니다. 이를 통해 스트림 데이터를 윈도우(창) 단위로 그룹화하고, 해당 윈도우에서 집계, 변환 또는 다른 작업을 수행할 수 있습니다. 이는 실시간 데이터 스트림에 대한 시간 기반 처리를 가능하게 합니다.

```java
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.TimeWindows;
import org.apache.kafka.streams.kstream.Windowed;
import org.apache.kafka.streams.kstream.Windows;

import java.time.Duration;
import java.util.Properties;

public class KafkaStreamsTumblingWindowsExample {
    public static void main(String[] args) {
        // Kafka Streams 애플리케이션 설정
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "kafka-streams-tumbling-windows-example");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        // StreamsBuilder 인스턴스 생성
        StreamsBuilder builder = new StreamsBuilder();

        // 입력 토픽을 KStream으로 읽기
        KStream<String, String> stream = builder.stream("input-topic");

        // Tumbling Window로 윈도우 생성
        KStream<Windowed<String>, Long> windowedStream = stream
                .groupByKey()
                .windowedBy(TimeWindows.of(Duration.ofMinutes(5)))
                .count(Materialized.as("windowed-store"));

        // 결과 출력
        windowedStream.toStream().foreach((window, count) -> {
            System.out.println("Window: " + window + ", Count: " + count);
        });

        // Kafka Streams 애플리케이션 실행
        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();

        // 애플리케이션 종료 시 Ctrl+C로 종료할 수 있도록 대기
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }
}
```







## 커넥트



## 아키텍처